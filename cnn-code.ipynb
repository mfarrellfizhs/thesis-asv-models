{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10301250,"sourceType":"datasetVersion","datasetId":6323715,"isSourceIdPinned":true},{"sourceId":10899850,"sourceType":"datasetVersion","datasetId":6774138},{"sourceId":10928212,"sourceType":"datasetVersion","datasetId":6794629},{"sourceId":10967403,"sourceType":"datasetVersion","datasetId":6823745,"isSourceIdPinned":true},{"sourceId":11077215,"sourceType":"datasetVersion","datasetId":6903859,"isSourceIdPinned":true}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. CNN Semua","metadata":{}},{"cell_type":"markdown","source":"## 1.1 Loading lib and data","metadata":{}},{"cell_type":"code","source":"import random\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nseed = 42\ntf.random.set_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-26T02:34:42.671794Z","iopub.execute_input":"2025-03-26T02:34:42.672518Z","iopub.status.idle":"2025-03-26T02:35:00.627360Z","shell.execute_reply.started":"2025-03-26T02:34:42.672486Z","shell.execute_reply":"2025-03-26T02:35:00.626387Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Loading all the data from dataset\nimport pandas as pd\nimport numpy as np\n\nDATA_PATH = '/kaggle/input/logmel-mfcc-set/'\n# DATA_PATH = '/kaggle/input/mfcc-no-filtering/'\n\n# ===== Dataset Notes =====\n# ```\n# Ver 6 logmel-mfcc-set = MFCC 13, LOGMEL 128, Group_Delay, Wav2Vec2\n# Ver 5 logmel-mfcc-set = MFCC 40 with augmentation\n# Ver 4 logmel-mfcc-set = MFCC 40\n# Ver 1 logmel-mfcc-set = MFCC & Logmel 13\n#\n# CURRENTLY IN: Version 1\n# ```\n\n# =========== MFCC ===========\nX_train_mfcc = pd.read_pickle(DATA_PATH + 'X_train_mfcc.pkl')\nX_dev_mfcc = pd.read_pickle(DATA_PATH + 'X_dev_mfcc.pkl')\nX_eval_mfcc = pd.read_pickle(DATA_PATH + 'X_eval_mfcc.pkl')\n\ny_train_mfcc = pd.read_pickle(DATA_PATH + 'y_train_mfcc.pkl')\ny_dev_mfcc = pd.read_pickle(DATA_PATH + 'y_dev_mfcc.pkl')\ny_eval_mfcc = pd.read_pickle(DATA_PATH + 'y_eval_mfcc.pkl')\n\n# ============================ SEPARATOR mfcc 40 no filtering ============================\nn_mfcc = 40\nfilters = 'sf'  # 'sf', 'wf', or 'swf'\n\n# Construct file names dynamically\nfile_suffix = f\"_wo_{filters}_{n_mfcc}.pkl\"\n\n# X_train_mfcc = pd.read_pickle(DATA_PATH + 'X_train_mfcc_wo_swf.pkl')\n# X_dev_mfcc = pd.read_pickle(DATA_PATH + 'X_dev_mfcc_wo_swf.pkl')\n# X_eval_mfcc = pd.read_pickle(DATA_PATH + 'X_eval_mfcc_wo_swf.pkl')\n\n# y_train_mfcc = pd.read_pickle(DATA_PATH + 'y_train_mfcc_wo_swf.pkl')\n# y_dev_mfcc = pd.read_pickle(DATA_PATH + 'y_dev_mfcc_wo_swf.pkl')\n# y_eval_mfcc = pd.read_pickle(DATA_PATH + 'y_eval_mfcc_wo_swf.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T02:35:00.628386Z","iopub.execute_input":"2025-03-26T02:35:00.628938Z","iopub.status.idle":"2025-03-26T02:35:54.164649Z","shell.execute_reply.started":"2025-03-26T02:35:00.628911Z","shell.execute_reply":"2025-03-26T02:35:54.163737Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"X_train_mfcc = X_train_mfcc.astype('float32')\ny_train_mfcc = y_train_mfcc.astype('float32')\nX_dev_mfcc = X_dev_mfcc.astype('float32')\ny_dev_mfcc = y_dev_mfcc.astype('float32')\nX_eval_mfcc = X_eval_mfcc.astype('float32')\ny_eval_mfcc = y_eval_mfcc.astype('float32')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T02:35:54.165983Z","iopub.execute_input":"2025-03-26T02:35:54.166273Z","iopub.status.idle":"2025-03-26T02:36:10.728794Z","shell.execute_reply.started":"2025-03-26T02:35:54.166252Z","shell.execute_reply":"2025-03-26T02:36:10.727889Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## 1.2 EER Calculation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, roc_auc_score, roc_curve\ndef eval_metr(y_true, y_pred, P_target=0.5):\n    # Compute ROC curve\n    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n    fnr = 1 - tpr  # False Negative Rate (Miss Rate)\n\n    # Compute EER\n    abs_diff = np.abs(fpr - fnr)\n    eer_index = np.argmin(abs_diff)\n    eer = (fpr[eer_index] + fnr[eer_index]) / 2\n\n    return eer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T02:36:18.333501Z","iopub.execute_input":"2025-03-26T02:36:18.333795Z","iopub.status.idle":"2025-03-26T02:36:18.338857Z","shell.execute_reply.started":"2025-03-26T02:36:18.333769Z","shell.execute_reply":"2025-03-26T02:36:18.338085Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## 1.3 Initializing CNN, Training, and Evaluating","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (\n    Input, Conv2D, BatchNormalization, GlobalAveragePooling2D, Dense, Dropout, MaxPooling2D,SpatialDropout2D,\n    Flatten, Activation, Add\n)\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n\n# Fix overfit / overconfident\nfrom tensorflow.keras.regularizers import l2\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.losses import Loss\n\ndef focal_loss(alpha=0.25, gamma=2.0):\n    def loss(y_true, y_pred):\n        y_true = K.cast(y_true, dtype=K.floatx())\n        bce = K.binary_crossentropy(y_true, y_pred)\n        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n        focal_term = K.pow(1 - p_t, gamma)\n        return alpha * focal_term * bce\n    return loss\n\ndef build_model(input_shape=(100, 40, 1)):\n    input_layer = Input(shape=input_shape)\n    \n    # Deeper CNN with L2 Regularization and Spatial Dropout\n    x = Conv2D(32, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(0.001))(input_layer)\n    x = BatchNormalization()(x)\n    x = SpatialDropout2D(0.2)(x)  # New Spatial Dropout\n\n    x = Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(0.001))(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2, 2))(x)\n\n    x = Conv2D(64, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(0.001))(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2,2))(x)\n\n    x = Dense(32, activation='relu', kernel_regularizer=l2(0.001))(x)\n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.5)(x)  # Increased dropout for stronger regularization\n    output_layer = Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001))(x)\n\n    model = Model(inputs=input_layer, outputs=output_layer)\n    return model\n\ndef cnn_maker(X_train, y_train, X_dev, y_dev, X_eval, y_eval):\n    X_train, X_dev, X_eval = [x[..., np.newaxis] for x in [X_train, X_dev, X_eval]]\n\n    model = build_model(X_train.shape[1:])\n    model.compile(optimizer=Adam(learning_rate=0.0001, clipnorm=1.0), loss=focal_loss(alpha=0.25, gamma=2.0), metrics=['accuracy'])\n    \n    callback = [\n        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n        EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n        ModelCheckpoint(f\"cnn.keras\", monitor='val_loss', save_best_only=True, verbose=1)\n    ]\n    \n    # Train the model\n    history = model.fit(X_train, y_train, epochs=50, batch_size=4, validation_data=(X_dev, y_dev),\n                        callbacks=callback)\n\n    # Model evaluation\n    dev_acc = model.evaluate(X_dev, y_dev, verbose=0)[1]\n    eval_acc = model.evaluate(X_eval, y_eval, verbose=0)[1]\n    \n    # Predictions for evaluation\n    y_pred_probs = model.predict(X_eval).flatten()\n    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n\n    # Classification report\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_eval, y_pred_labels, target_names=[\"spoof\", \"bonafide\"], digits=2))\n\n    # Compute EER\n    eer = eval_metr(y_eval, y_pred_probs)\n    print(f\"EER: {eer * 100:.2f}%\")\n\n    return model, history\n\n\ndef plot_training_history(history):\n    plt.figure(figsize=(12, 5))\n\n    # Plot Loss\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['loss'], label='Training Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title(f'Train vs Val Loss')\n    plt.legend()\n\n    # Plot Accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['accuracy'], label='Training Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title(f'Train vs Val Accuracy')\n    plt.legend()\n\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T02:36:11.414727Z","iopub.execute_input":"2025-03-26T02:36:11.415269Z","iopub.status.idle":"2025-03-26T02:36:11.540087Z","shell.execute_reply.started":"2025-03-26T02:36:11.415243Z","shell.execute_reply":"2025-03-26T02:36:11.539285Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"tf.random.set_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\n# del cnn_mfcc_model\ncnn_mfcc_model, history = cnn_maker(X_train_mfcc, y_train_mfcc, X_dev_mfcc, y_dev_mfcc, X_eval_mfcc, y_eval_mfcc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T06:56:34.515872Z","iopub.execute_input":"2025-03-21T06:56:34.516124Z","iopub.status.idle":"2025-03-21T07:13:29.001374Z","shell.execute_reply.started":"2025-03-21T06:56:34.516091Z","shell.execute_reply":"2025-03-21T07:13:29.000454Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m5383/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8475 - loss: 0.1379\nEpoch 1: val_loss improved from inf to 0.03295, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - accuracy: 0.8476 - loss: 0.1378 - val_accuracy: 0.9748 - val_loss: 0.0329 - learning_rate: 1.0000e-04\nEpoch 2/50\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.0301\nEpoch 2: val_loss improved from 0.03295 to 0.01211, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9573 - loss: 0.0301 - val_accuracy: 0.9920 - val_loss: 0.0121 - learning_rate: 1.0000e-04\nEpoch 3/50\n\u001b[1m5391/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9792 - loss: 0.0140\nEpoch 3: val_loss improved from 0.01211 to 0.00772, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0140 - val_accuracy: 0.9966 - val_loss: 0.0077 - learning_rate: 1.0000e-04\nEpoch 4/50\n\u001b[1m5381/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9832 - loss: 0.0105\nEpoch 4: val_loss improved from 0.00772 to 0.00681, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9832 - loss: 0.0105 - val_accuracy: 0.9962 - val_loss: 0.0068 - learning_rate: 1.0000e-04\nEpoch 5/50\n\u001b[1m5382/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9861 - loss: 0.0090\nEpoch 5: val_loss improved from 0.00681 to 0.00599, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.0090 - val_accuracy: 0.9975 - val_loss: 0.0060 - learning_rate: 1.0000e-04\nEpoch 6/50\n\u001b[1m5387/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9875 - loss: 0.0080\nEpoch 6: val_loss improved from 0.00599 to 0.00574, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.0080 - val_accuracy: 0.9970 - val_loss: 0.0057 - learning_rate: 1.0000e-04\nEpoch 7/50\n\u001b[1m5377/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.0077\nEpoch 7: val_loss improved from 0.00574 to 0.00553, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9877 - loss: 0.0077 - val_accuracy: 0.9971 - val_loss: 0.0055 - learning_rate: 1.0000e-04\nEpoch 8/50\n\u001b[1m5380/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9889 - loss: 0.0071\nEpoch 8: val_loss improved from 0.00553 to 0.00493, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.0071 - val_accuracy: 0.9966 - val_loss: 0.0049 - learning_rate: 1.0000e-04\nEpoch 9/50\n\u001b[1m5387/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9885 - loss: 0.0069\nEpoch 9: val_loss improved from 0.00493 to 0.00470, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.0069 - val_accuracy: 0.9968 - val_loss: 0.0047 - learning_rate: 1.0000e-04\nEpoch 10/50\n\u001b[1m5389/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9888 - loss: 0.0068\nEpoch 10: val_loss did not improve from 0.00470\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9888 - loss: 0.0068 - val_accuracy: 0.9966 - val_loss: 0.0048 - learning_rate: 1.0000e-04\nEpoch 11/50\n\u001b[1m5378/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0063\nEpoch 11: val_loss improved from 0.00470 to 0.00439, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0063 - val_accuracy: 0.9975 - val_loss: 0.0044 - learning_rate: 1.0000e-04\nEpoch 12/50\n\u001b[1m5383/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.0063\nEpoch 12: val_loss improved from 0.00439 to 0.00434, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9900 - loss: 0.0063 - val_accuracy: 0.9977 - val_loss: 0.0043 - learning_rate: 1.0000e-04\nEpoch 13/50\n\u001b[1m5385/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9895 - loss: 0.0060\nEpoch 13: val_loss improved from 0.00434 to 0.00413, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0060 - val_accuracy: 0.9981 - val_loss: 0.0041 - learning_rate: 1.0000e-04\nEpoch 14/50\n\u001b[1m5382/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9896 - loss: 0.0060\nEpoch 14: val_loss improved from 0.00413 to 0.00398, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0060 - val_accuracy: 0.9978 - val_loss: 0.0040 - learning_rate: 1.0000e-04\nEpoch 15/50\n\u001b[1m5383/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9890 - loss: 0.0059\nEpoch 15: val_loss did not improve from 0.00398\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9890 - loss: 0.0059 - val_accuracy: 0.9971 - val_loss: 0.0041 - learning_rate: 1.0000e-04\nEpoch 16/50\n\u001b[1m5385/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9903 - loss: 0.0057\nEpoch 16: val_loss did not improve from 0.00398\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9903 - loss: 0.0057 - val_accuracy: 0.9974 - val_loss: 0.0043 - learning_rate: 1.0000e-04\nEpoch 17/50\n\u001b[1m5382/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9904 - loss: 0.0055\nEpoch 17: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\nEpoch 17: val_loss did not improve from 0.00398\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.0055 - val_accuracy: 0.9974 - val_loss: 0.0042 - learning_rate: 1.0000e-04\nEpoch 18/50\n\u001b[1m5387/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0051\nEpoch 18: val_loss improved from 0.00398 to 0.00353, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0051 - val_accuracy: 0.9982 - val_loss: 0.0035 - learning_rate: 5.0000e-05\nEpoch 19/50\n\u001b[1m5379/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0047\nEpoch 19: val_loss improved from 0.00353 to 0.00352, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9918 - loss: 0.0047 - val_accuracy: 0.9976 - val_loss: 0.0035 - learning_rate: 5.0000e-05\nEpoch 20/50\n\u001b[1m5384/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0044\nEpoch 20: val_loss improved from 0.00352 to 0.00338, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9936 - loss: 0.0044 - val_accuracy: 0.9976 - val_loss: 0.0034 - learning_rate: 5.0000e-05\nEpoch 21/50\n\u001b[1m5384/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0046\nEpoch 21: val_loss improved from 0.00338 to 0.00329, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0046 - val_accuracy: 0.9974 - val_loss: 0.0033 - learning_rate: 5.0000e-05\nEpoch 22/50\n\u001b[1m5380/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0043\nEpoch 22: val_loss improved from 0.00329 to 0.00323, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9936 - loss: 0.0043 - val_accuracy: 0.9982 - val_loss: 0.0032 - learning_rate: 5.0000e-05\nEpoch 23/50\n\u001b[1m5390/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0045\nEpoch 23: val_loss improved from 0.00323 to 0.00322, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.0045 - val_accuracy: 0.9979 - val_loss: 0.0032 - learning_rate: 5.0000e-05\nEpoch 24/50\n\u001b[1m5394/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0044\nEpoch 24: val_loss did not improve from 0.00322\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.0044 - val_accuracy: 0.9982 - val_loss: 0.0034 - learning_rate: 5.0000e-05\nEpoch 25/50\n\u001b[1m5387/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9935 - loss: 0.0044\nEpoch 25: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\nEpoch 25: val_loss improved from 0.00322 to 0.00315, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0044 - val_accuracy: 0.9977 - val_loss: 0.0031 - learning_rate: 5.0000e-05\nEpoch 26/50\n\u001b[1m5389/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0041\nEpoch 26: val_loss improved from 0.00315 to 0.00307, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0041 - val_accuracy: 0.9979 - val_loss: 0.0031 - learning_rate: 2.5000e-05\nEpoch 27/50\n\u001b[1m5387/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9933 - loss: 0.0041\nEpoch 27: val_loss improved from 0.00307 to 0.00306, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9933 - loss: 0.0041 - val_accuracy: 0.9979 - val_loss: 0.0031 - learning_rate: 2.5000e-05\nEpoch 28/50\n\u001b[1m5391/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0040\nEpoch 28: val_loss did not improve from 0.00306\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9934 - loss: 0.0040 - val_accuracy: 0.9973 - val_loss: 0.0031 - learning_rate: 2.5000e-05\nEpoch 29/50\n\u001b[1m5392/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0040\nEpoch 29: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\nEpoch 29: val_loss improved from 0.00306 to 0.00303, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9936 - loss: 0.0040 - val_accuracy: 0.9983 - val_loss: 0.0030 - learning_rate: 2.5000e-05\nEpoch 30/50\n\u001b[1m5379/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0038\nEpoch 30: val_loss improved from 0.00303 to 0.00297, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9936 - loss: 0.0038 - val_accuracy: 0.9976 - val_loss: 0.0030 - learning_rate: 1.2500e-05\nEpoch 31/50\n\u001b[1m5393/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0038\nEpoch 31: val_loss improved from 0.00297 to 0.00292, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9950 - loss: 0.0038 - val_accuracy: 0.9982 - val_loss: 0.0029 - learning_rate: 1.2500e-05\nEpoch 32/50\n\u001b[1m5380/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0037\nEpoch 32: val_loss improved from 0.00292 to 0.00290, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0037 - val_accuracy: 0.9983 - val_loss: 0.0029 - learning_rate: 1.2500e-05\nEpoch 33/50\n\u001b[1m5394/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0037\nEpoch 33: val_loss did not improve from 0.00290\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0037 - val_accuracy: 0.9974 - val_loss: 0.0030 - learning_rate: 1.2500e-05\nEpoch 34/50\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0037\nEpoch 34: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n\nEpoch 34: val_loss improved from 0.00290 to 0.00287, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0037 - val_accuracy: 0.9981 - val_loss: 0.0029 - learning_rate: 1.2500e-05\nEpoch 35/50\n\u001b[1m5389/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0037\nEpoch 35: val_loss did not improve from 0.00287\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0037 - val_accuracy: 0.9981 - val_loss: 0.0029 - learning_rate: 6.2500e-06\nEpoch 36/50\n\u001b[1m5389/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0037\nEpoch 36: val_loss improved from 0.00287 to 0.00287, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.0037 - val_accuracy: 0.9982 - val_loss: 0.0029 - learning_rate: 6.2500e-06\nEpoch 37/50\n\u001b[1m5384/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0036\nEpoch 37: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n\nEpoch 37: val_loss did not improve from 0.00287\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.0036 - val_accuracy: 0.9980 - val_loss: 0.0029 - learning_rate: 6.2500e-06\nEpoch 38/50\n\u001b[1m5378/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0035\nEpoch 38: val_loss improved from 0.00287 to 0.00285, saving model to cnn.keras\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0035 - val_accuracy: 0.9984 - val_loss: 0.0028 - learning_rate: 3.1250e-06\nEpoch 39/50\n\u001b[1m5393/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0036\nEpoch 39: val_loss did not improve from 0.00285\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0036 - val_accuracy: 0.9982 - val_loss: 0.0029 - learning_rate: 3.1250e-06\nEpoch 40/50\n\u001b[1m5377/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0035\nEpoch 40: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n\nEpoch 40: val_loss did not improve from 0.00285\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0035 - val_accuracy: 0.9977 - val_loss: 0.0029 - learning_rate: 3.1250e-06\nEpoch 41/50\n\u001b[1m5388/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0036\nEpoch 41: val_loss did not improve from 0.00285\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9944 - loss: 0.0036 - val_accuracy: 0.9982 - val_loss: 0.0029 - learning_rate: 1.5625e-06\nEpoch 42/50\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0037\nEpoch 42: val_loss did not improve from 0.00285\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0037 - val_accuracy: 0.9981 - val_loss: 0.0029 - learning_rate: 1.5625e-06\nEpoch 43/50\n\u001b[1m5376/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0037\nEpoch 43: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n\nEpoch 43: val_loss did not improve from 0.00285\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9950 - loss: 0.0037 - val_accuracy: 0.9982 - val_loss: 0.0029 - learning_rate: 1.5625e-06\nEpoch 44/50\n\u001b[1m5386/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0036\nEpoch 44: val_loss did not improve from 0.00285\n\u001b[1m5395/5395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0036 - val_accuracy: 0.9983 - val_loss: 0.0029 - learning_rate: 7.8125e-07\n\u001b[1m2073/2073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       spoof       1.00      0.84      0.91     58968\n    bonafide       0.43      0.99      0.60      7355\n\n    accuracy                           0.85     66323\n   macro avg       0.72      0.91      0.76     66323\nweighted avg       0.94      0.85      0.88     66323\n\nEER: 10.09% | min t-DCF: 0.9392\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"cnn_mfcc_model.save(\"cnn_40_no_wf_optimized.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T05:44:15.155061Z","iopub.execute_input":"2025-03-21T05:44:15.155387Z","iopub.status.idle":"2025-03-21T05:44:15.209523Z","shell.execute_reply.started":"2025-03-21T05:44:15.155354Z","shell.execute_reply":"2025-03-21T05:44:15.208962Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"plot_training_history(history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T07:13:29.002386Z","iopub.execute_input":"2025-03-21T07:13:29.002667Z","iopub.status.idle":"2025-03-21T07:13:29.389044Z","shell.execute_reply.started":"2025-03-21T07:13:29.002643Z","shell.execute_reply":"2025-03-21T07:13:29.388246Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x500 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"tf.random.set_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\n\n# Evaluate the model and get the predicted probabilities\ny_pred_dev = cnn_mfcc_model.predict(X_dev_mfcc)  # Get the predicted probabilities for eval data\ny_pred_dev_probs_cnn_mfcc = y_pred_dev[:, 0]  # Probability for the positive class (class 1)\n\nroc_auc = roc_auc_score(y_dev_mfcc, y_pred_dev_probs_cnn_mfcc)\nprint(f'ROC AUC: {roc_auc}')\nprint(classification_report(y_dev_mfcc, (y_pred_dev_probs_cnn_mfcc >= 0.5).astype(int)))\n\n# Evaluate the metrics using eval_metr\neer_cnn_mfcc_dev = eval_metr(y_dev_mfcc, y_pred_dev_probs_cnn_mfcc)\n\n# Print the results\nprint(f\"CNN EER on validation data: {eer_cnn_mfcc_dev * 100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tf.random.set_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\n\n# Evaluate the model and get the predicted probabilities\ny_pred_eval = cnn_mfcc_model.predict(X_eval_mfcc)  # Get the predicted probabilities for eval data\ny_pred_eval_probs_cnn_mfcc = y_pred_eval[:, 0]  # Probability for the positive class (class 1)\n\nroc_auc = roc_auc_score(y_eval_mfcc, y_pred_eval_probs_cnn_mfcc)\nprint(f'ROC AUC: {roc_auc}')\nprint(classification_report(y_eval_mfcc, (y_pred_eval_probs_cnn_mfcc >= 0.5).astype(int)))\n\n# Evaluate the metrics using eval_metr\neer_cnn_mfcc_eval = eval_metr(y_eval_mfcc, y_pred_eval_probs_cnn_mfcc)\n\n# Print the results\nprint(f\"CNN EER on testing data: {eer_cnn_mfcc_eval * 100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. CNN Each System_ID","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport ast\nimport random\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T02:36:11.541001Z","iopub.execute_input":"2025-03-26T02:36:11.541306Z","iopub.status.idle":"2025-03-26T02:36:11.566661Z","shell.execute_reply.started":"2025-03-26T02:36:11.541278Z","shell.execute_reply":"2025-03-26T02:36:11.565743Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## 2.1 Function to load data & EER calc","metadata":{}},{"cell_type":"code","source":"def load_separate_data(base_path, selected_systems):\n    all_data = []\n    for system_id in [\"bonafide\"] + [f\"A{str(i).zfill(2)}\" for i in range(1, 20)]:\n        if system_id not in selected_systems:\n            continue  # Skip unselected system_ids\n        \n        file_path = os.path.join(base_path, f\"{system_id}.csv\")\n        if os.path.exists(file_path):\n            df = pd.read_csv(file_path)\n            all_data.append(df)\n\n    if all_data:\n        return pd.concat(all_data, ignore_index=True)\n    else:\n        return pd.DataFrame(columns=[\"system_id\", \"features\", \"label\"]) \n\n# Convert features from string to numpy arrays\ndef process_features(features_column):\n    processed_features = []\n\n    for f in features_column:\n        feature_array = np.array(eval(f), dtype=np.float32)  # Convert string to NumPy array\n        feature_array = feature_array.reshape(40, 100)  # Reshape to (40, 100)\n        processed_features.append(feature_array)\n\n    return np.array(processed_features, dtype=np.float32)\n\n# Split the dataset\ndef prepare_data(df, bonafide_df, test_size=0.2, val_size=0.1):\n    spoof_df = df[df[\"label\"] == 0]\n    bonafide_df = bonafide_df.sample(n=len(spoof_df), replace=True)  # Balance bonafide count\n\n    df_balanced = pd.concat([spoof_df, bonafide_df]).sample(frac=1)  # Shuffle\n\n    features = process_features(df_balanced[\"features\"])\n    labels = df_balanced[\"label\"].values\n\n    X_train, X_temp, y_train, y_temp = train_test_split(features, labels, test_size=(test_size + val_size), stratify=labels)\n    X_dev, X_eval, y_dev, y_eval = train_test_split(X_temp, y_temp, test_size=(val_size / (test_size + val_size)), stratify=y_temp)\n\n    return X_train, y_train, X_dev, y_dev, X_eval, y_eval\n\nfrom sklearn.metrics import classification_report, roc_auc_score, roc_curve\ndef eval_metr(y_true, y_pred, P_target=0.5):\n    # Compute ROC curve\n    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n    fnr = 1 - tpr  # False Negative Rate (Miss Rate)\n\n    # Compute EER\n    abs_diff = np.abs(fpr - fnr)\n    eer_index = np.argmin(abs_diff)\n    eer = (fpr[eer_index] + fnr[eer_index]) / 2\n    return eer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T02:36:24.674806Z","iopub.execute_input":"2025-03-26T02:36:24.675142Z","iopub.status.idle":"2025-03-26T02:36:24.683698Z","shell.execute_reply.started":"2025-03-26T02:36:24.675108Z","shell.execute_reply":"2025-03-26T02:36:24.682963Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## 2.2 Model Arch","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (\n    Input, Conv2D, BatchNormalization, GlobalAveragePooling2D, Dense, Dropout, MaxPooling2D,SpatialDropout2D,\n    Flatten, Activation, Add\n)\n\n# CNN Model\ndef build_model(input_shape=(100, 40, 1)):\n    input_layer = Input(shape=input_shape)\n    \n    # Deeper CNN\n    x = Conv2D(32, (3, 3), padding='same', activation='relu')(input_layer)\n    x = BatchNormalization()(x)\n\n    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2, 2))(x)\n\n    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    \n    x = MaxPooling2D()(x)\n    x = Dense(32, activation='relu')(x)\n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.2)(x)  # Reduced dropout for better learning\n    output_layer = Dense(1, activation='sigmoid')(x)\n\n    model = Model(inputs=input_layer, outputs=output_layer)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T02:36:27.377645Z","iopub.execute_input":"2025-03-26T02:36:27.377933Z","iopub.status.idle":"2025-03-26T02:36:27.383947Z","shell.execute_reply.started":"2025-03-26T02:36:27.377909Z","shell.execute_reply":"2025-03-26T02:36:27.383166Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## 2.3 Training and evaluation functions","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\n\n# Fix overfit / overconfident\nfrom tensorflow.keras.regularizers import l2\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.losses import Loss\n\ndef focal_loss(alpha=0.25, gamma=2.0):\n    def loss(y_true, y_pred):\n        y_true = K.cast(y_true, dtype=K.floatx())\n        bce = K.binary_crossentropy(y_true, y_pred)\n        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n        focal_term = K.pow(1 - p_t, gamma)\n        return alpha * focal_term * bce\n    return loss\n\ndef train_and_evaluate(X_train, y_train, X_dev, y_dev, X_eval, y_eval, system_id):\n    X_train, X_dev, X_eval = [x[..., np.newaxis] for x in [X_train, X_dev, X_eval]]\n\n    model = build_model(X_train.shape[1:])\n    model.compile(optimizer=Adam(learning_rate=0.0001, clipnorm=1.0), loss=\"binary_crossentropy\", metrics=['accuracy'])\n\n    history = model.fit(X_train, y_train, epochs=15, batch_size=4, validation_data=(X_dev, y_dev))\n\n    # Model evaluation\n    dev_acc = model.evaluate(X_dev, y_dev, verbose=0)[1]\n    eval_acc = model.evaluate(X_eval, y_eval, verbose=0)[1]\n    \n    # Predictions for evaluation\n    y_pred_probs = model.predict(X_eval).flatten()\n    y_pred_labels = (y_pred_probs > 0.5).astype(int)\n\n    # Classification report\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_eval, y_pred_labels, target_names=[\"spoof\", \"bonafide\"], digits=2))\n\n    # Compute EER & t-DCF\n    eer = eval_metr(y_eval, y_pred_probs)\n    print(f\"EER: {eer:.4f}\")\n\n    return model\n\n\ndef plot_training_history(history, system_id):\n    plt.figure(figsize=(12, 5))\n\n    # Plot Loss\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['loss'], label='Training Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title(f'Train vs Val Loss on {system_id}')\n    plt.legend()\n\n    # Plot Accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['accuracy'], label='Training Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title(f'Train vs Val Accuracy on {system_id}')\n    plt.legend()\n\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T02:36:32.857222Z","iopub.execute_input":"2025-03-26T02:36:32.857499Z","iopub.status.idle":"2025-03-26T02:36:32.866979Z","shell.execute_reply.started":"2025-03-26T02:36:32.857480Z","shell.execute_reply":"2025-03-26T02:36:32.866243Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## 2.4 Running all","metadata":{}},{"cell_type":"code","source":"base_path = \"/kaggle/input/mfcc-sid\"\ndf_bonafide = pd.read_csv(f\"{base_path}/bonafide.csv\")\nselected_systems = [\"A01\", \"A02\", \"A03\", \"A04\", \"A05\", \"A06\", \"A07\", \"A08\", \"A09\", \"A10\"]\ndf = load_separate_data(base_path, selected_systems)\n\nfor system_id in df[\"system_id\"].unique():\n    print(f\"\\n🔹 Training for {system_id} 🔹\")\n    \n    df_filtered = df[df[\"system_id\"] == system_id]\n    \n    X_train, y_train, X_dev, y_dev, X_eval, y_eval = prepare_data(df_filtered, df_bonafide)\n\n    model, history = train_and_evaluate(X_train, y_train, X_dev, y_dev, X_eval, y_eval, system_id)\n\n    # plot_training_history(history, system_id)\n    \n    # Free up memory after training\n    del model  \n    K.clear_session()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T02:36:36.538943Z","iopub.execute_input":"2025-03-26T02:36:36.539317Z","iopub.status.idle":"2025-03-26T03:16:00.763660Z","shell.execute_reply.started":"2025-03-26T02:36:36.539286Z","shell.execute_reply":"2025-03-26T03:16:00.762902Z"}},"outputs":[{"name":"stdout","text":"\n🔹 Training for A01 🔹\nEpoch 1/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.9345 - loss: 0.2124 - val_accuracy: 1.0000 - val_loss: 0.0112\nEpoch 2/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0215 - val_accuracy: 1.0000 - val_loss: 0.0025\nEpoch 3/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 0.0015\nEpoch 4/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 6.6134e-04\nEpoch 5/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 6.8149e-04\nEpoch 6/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 3.4569e-04\nEpoch 7/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 7.0945e-04\nEpoch 8/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 1.2122e-04\nEpoch 9/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.9997 - val_loss: 5.1537e-04\nEpoch 10/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 6.4422e-04\nEpoch 11/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 6.6710e-04 - val_accuracy: 1.0000 - val_loss: 2.5284e-04\nEpoch 12/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 7.7585e-04 - val_accuracy: 1.0000 - val_loss: 4.3756e-05\nEpoch 13/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 7.0228e-04 - val_accuracy: 1.0000 - val_loss: 1.6860e-04\nEpoch 14/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 5.2956e-04 - val_accuracy: 1.0000 - val_loss: 4.9657e-05\nEpoch 15/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8520e-04 - val_accuracy: 1.0000 - val_loss: 6.2173e-05\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       spoof       1.00      1.00      1.00       752\n    bonafide       1.00      1.00      1.00       752\n\n    accuracy                           1.00      1504\n   macro avg       1.00      1.00      1.00      1504\nweighted avg       1.00      1.00      1.00      1504\n\nEER: 0.0000 | min t-DCF: 0.0000\n\n🔹 Training for A02 🔹\nEpoch 1/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9183 - loss: 0.2415 - val_accuracy: 1.0000 - val_loss: 0.0066\nEpoch 2/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0133 - val_accuracy: 1.0000 - val_loss: 9.9275e-04\nEpoch 3/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 2.4774e-04\nEpoch 4/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 2.8494e-04\nEpoch 5/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.1096e-04 - val_accuracy: 1.0000 - val_loss: 8.6184e-06\nEpoch 6/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.8974e-04 - val_accuracy: 1.0000 - val_loss: 5.6234e-06\nEpoch 7/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.9992e-05 - val_accuracy: 1.0000 - val_loss: 9.5164e-06\nEpoch 8/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 7.3529e-04 - val_accuracy: 1.0000 - val_loss: 4.0244e-06\nEpoch 9/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1285e-05 - val_accuracy: 1.0000 - val_loss: 2.6377e-04\nEpoch 10/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.3363e-05 - val_accuracy: 1.0000 - val_loss: 7.3220e-07\nEpoch 11/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.0115e-05 - val_accuracy: 1.0000 - val_loss: 1.6851e-06\nEpoch 12/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9523e-05 - val_accuracy: 1.0000 - val_loss: 9.1487e-07\nEpoch 13/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.1738e-05 - val_accuracy: 1.0000 - val_loss: 4.3024e-07\nEpoch 14/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1204e-04 - val_accuracy: 1.0000 - val_loss: 1.0960e-06\nEpoch 15/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4246e-05 - val_accuracy: 1.0000 - val_loss: 5.6719e-07\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       spoof       1.00      1.00      1.00       752\n    bonafide       1.00      1.00      1.00       752\n\n    accuracy                           1.00      1504\n   macro avg       1.00      1.00      1.00      1504\nweighted avg       1.00      1.00      1.00      1504\n\nEER: 0.0000 | min t-DCF: 0.0000\n\n🔹 Training for A03 🔹\nEpoch 1/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9274 - loss: 0.2274 - val_accuracy: 1.0000 - val_loss: 0.0101\nEpoch 2/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0152 - val_accuracy: 1.0000 - val_loss: 0.0018\nEpoch 3/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0044 - val_accuracy: 0.9997 - val_loss: 0.0020\nEpoch 4/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 5.7521e-04\nEpoch 5/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 1.6956e-04\nEpoch 6/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 6.1307e-04 - val_accuracy: 1.0000 - val_loss: 4.0539e-05\nEpoch 7/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1422e-04 - val_accuracy: 0.9997 - val_loss: 0.0024\nEpoch 8/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.4321e-04 - val_accuracy: 1.0000 - val_loss: 1.2653e-05\nEpoch 9/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 7.7336e-04 - val_accuracy: 1.0000 - val_loss: 2.4501e-04\nEpoch 10/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 5.7688e-04 - val_accuracy: 1.0000 - val_loss: 5.3599e-05\nEpoch 11/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 3.7906e-04 - val_accuracy: 1.0000 - val_loss: 1.7450e-04\nEpoch 12/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 2.1763e-04 - val_accuracy: 1.0000 - val_loss: 9.3266e-06\nEpoch 13/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 8.8871e-06\nEpoch 14/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4942e-04 - val_accuracy: 1.0000 - val_loss: 3.3311e-05\nEpoch 15/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1895e-04 - val_accuracy: 1.0000 - val_loss: 1.5049e-05\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       spoof       1.00      1.00      1.00       752\n    bonafide       1.00      1.00      1.00       752\n\n    accuracy                           1.00      1504\n   macro avg       1.00      1.00      1.00      1504\nweighted avg       1.00      1.00      1.00      1504\n\nEER: 0.0000 | min t-DCF: 0.0000\n\n🔹 Training for A04 🔹\nEpoch 1/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.8597 - loss: 0.3515 - val_accuracy: 0.9917 - val_loss: 0.0508\nEpoch 2/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.0696 - val_accuracy: 0.9957 - val_loss: 0.0254\nEpoch 3/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0304 - val_accuracy: 0.9950 - val_loss: 0.0204\nEpoch 4/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0226 - val_accuracy: 0.9960 - val_loss: 0.0178\nEpoch 5/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0139 - val_accuracy: 0.9970 - val_loss: 0.0146\nEpoch 6/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0161 - val_accuracy: 0.9967 - val_loss: 0.0152\nEpoch 7/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0128 - val_accuracy: 0.9970 - val_loss: 0.0132\nEpoch 8/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0091 - val_accuracy: 0.9977 - val_loss: 0.0124\nEpoch 9/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0108 - val_accuracy: 0.9977 - val_loss: 0.0103\nEpoch 10/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0088 - val_accuracy: 0.9970 - val_loss: 0.0124\nEpoch 11/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0084 - val_accuracy: 0.9963 - val_loss: 0.0126\nEpoch 12/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0077 - val_accuracy: 0.9977 - val_loss: 0.0102\nEpoch 13/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0071 - val_accuracy: 0.9977 - val_loss: 0.0091\nEpoch 14/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0075 - val_accuracy: 0.9980 - val_loss: 0.0093\nEpoch 15/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0072 - val_accuracy: 0.9980 - val_loss: 0.0094\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       spoof       1.00      1.00      1.00       752\n    bonafide       1.00      1.00      1.00       752\n\n    accuracy                           1.00      1504\n   macro avg       1.00      1.00      1.00      1504\nweighted avg       1.00      1.00      1.00      1504\n\nEER: 0.0027 | min t-DCF: 0.0027\n\n🔹 Training for A05 🔹\nEpoch 1/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.8794 - loss: 0.3168 - val_accuracy: 0.9987 - val_loss: 0.0276\nEpoch 2/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.0398 - val_accuracy: 0.9997 - val_loss: 0.0085\nEpoch 3/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0173 - val_accuracy: 0.9997 - val_loss: 0.0031\nEpoch 4/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 0.0013\nEpoch 5/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 8.1299e-04\nEpoch 6/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 4.1493e-04\nEpoch 7/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0023 - val_accuracy: 0.9997 - val_loss: 0.0020\nEpoch 8/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9997 - val_loss: 0.0018\nEpoch 9/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 2.0468e-04\nEpoch 10/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 1.6196e-04\nEpoch 11/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 2.3168e-04\nEpoch 12/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 8.7132e-04 - val_accuracy: 1.0000 - val_loss: 8.4599e-05\nEpoch 13/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 8.3930e-04 - val_accuracy: 1.0000 - val_loss: 9.0498e-05\nEpoch 14/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 5.8614e-04 - val_accuracy: 1.0000 - val_loss: 1.5792e-04\nEpoch 15/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.6844e-04 - val_accuracy: 1.0000 - val_loss: 4.5665e-05\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       spoof       1.00      1.00      1.00       752\n    bonafide       1.00      1.00      1.00       752\n\n    accuracy                           1.00      1504\n   macro avg       1.00      1.00      1.00      1504\nweighted avg       1.00      1.00      1.00      1504\n\nEER: 0.0000 | min t-DCF: 0.0000\n\n🔹 Training for A06 🔹\nEpoch 1/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.7674 - loss: 0.4860 - val_accuracy: 0.9744 - val_loss: 0.1034\nEpoch 2/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9479 - loss: 0.1530 - val_accuracy: 0.9731 - val_loss: 0.0831\nEpoch 3/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.0989 - val_accuracy: 0.9910 - val_loss: 0.0352\nEpoch 4/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9714 - loss: 0.0770 - val_accuracy: 0.9930 - val_loss: 0.0279\nEpoch 5/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9801 - loss: 0.0598 - val_accuracy: 0.9933 - val_loss: 0.0231\nEpoch 6/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9825 - loss: 0.0471 - val_accuracy: 0.9904 - val_loss: 0.0345\nEpoch 7/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9860 - loss: 0.0406 - val_accuracy: 0.9980 - val_loss: 0.0097\nEpoch 8/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 0.0324 - val_accuracy: 0.9947 - val_loss: 0.0158\nEpoch 9/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9897 - loss: 0.0326 - val_accuracy: 0.9970 - val_loss: 0.0125\nEpoch 10/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9904 - loss: 0.0280 - val_accuracy: 0.9957 - val_loss: 0.0171\nEpoch 11/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9939 - loss: 0.0235 - val_accuracy: 0.9963 - val_loss: 0.0131\nEpoch 12/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9928 - loss: 0.0228 - val_accuracy: 0.9980 - val_loss: 0.0070\nEpoch 13/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0215 - val_accuracy: 0.9977 - val_loss: 0.0092\nEpoch 14/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0195 - val_accuracy: 0.9987 - val_loss: 0.0046\nEpoch 15/15\n\u001b[1m2631/2631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.0186 - val_accuracy: 0.9983 - val_loss: 0.0063\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       spoof       1.00      1.00      1.00       752\n    bonafide       1.00      1.00      1.00       752\n\n    accuracy                           1.00      1504\n   macro avg       1.00      1.00      1.00      1504\nweighted avg       1.00      1.00      1.00      1504\n\nEER: 0.0007 | min t-DCF: 0.0013\n\n🔹 Training for A07 🔹\nEpoch 1/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.9240 - loss: 0.2579 - val_accuracy: 0.9990 - val_loss: 0.0215\nEpoch 2/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0314 - val_accuracy: 0.9990 - val_loss: 0.0068\nEpoch 3/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0141 - val_accuracy: 0.9995 - val_loss: 0.0045\nEpoch 4/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0083 - val_accuracy: 0.9990 - val_loss: 0.0047\nEpoch 5/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0059 - val_accuracy: 0.9990 - val_loss: 0.0023\nEpoch 6/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0051 - val_accuracy: 0.9990 - val_loss: 0.0022\nEpoch 7/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0025 - val_accuracy: 0.9995 - val_loss: 0.0024\nEpoch 8/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0023 - val_accuracy: 0.9995 - val_loss: 0.0018\nEpoch 9/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0021 - val_accuracy: 0.9995 - val_loss: 0.0015\nEpoch 10/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0018 - val_accuracy: 0.9995 - val_loss: 0.0016\nEpoch 11/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.9995 - val_loss: 9.8755e-04\nEpoch 12/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9985 - val_loss: 0.0021\nEpoch 13/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.9995 - val_loss: 7.2958e-04\nEpoch 14/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 4.7116e-04\nEpoch 15/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 6.7687e-04 - val_accuracy: 1.0000 - val_loss: 6.8162e-04\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       spoof       1.00      1.00      1.00       492\n    bonafide       1.00      1.00      1.00       491\n\n    accuracy                           1.00       983\n   macro avg       1.00      1.00      1.00       983\nweighted avg       1.00      1.00      1.00       983\n\nEER: 0.0000 | min t-DCF: 0.0000\n\n🔹 Training for A08 🔹\nEpoch 1/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9263 - loss: 0.2599 - val_accuracy: 1.0000 - val_loss: 0.0265\nEpoch 2/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9916 - loss: 0.0450 - val_accuracy: 0.9985 - val_loss: 0.0176\nEpoch 3/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0203 - val_accuracy: 0.9990 - val_loss: 0.0138\nEpoch 4/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0118 - val_accuracy: 1.0000 - val_loss: 0.0038\nEpoch 5/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0097 - val_accuracy: 1.0000 - val_loss: 0.0029\nEpoch 6/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0069 - val_accuracy: 0.9939 - val_loss: 0.0146\nEpoch 7/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0061 - val_accuracy: 0.9975 - val_loss: 0.0085\nEpoch 8/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0055 - val_accuracy: 0.9995 - val_loss: 0.0034\nEpoch 9/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 8.9282e-04\nEpoch 10/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.9995 - val_loss: 0.0030\nEpoch 11/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0023\nEpoch 12/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 8.7823e-04\nEpoch 13/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 6.4271e-04\nEpoch 14/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 2.2921e-04\nEpoch 15/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 3.7826e-04\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       spoof       1.00      1.00      1.00       491\n    bonafide       1.00      1.00      1.00       492\n\n    accuracy                           1.00       983\n   macro avg       1.00      1.00      1.00       983\nweighted avg       1.00      1.00      1.00       983\n\nEER: 0.0000 | min t-DCF: 0.0000\n\n🔹 Training for A09 🔹\nEpoch 1/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9086 - loss: 0.2753 - val_accuracy: 1.0000 - val_loss: 0.0217\nEpoch 2/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0299 - val_accuracy: 1.0000 - val_loss: 0.0052\nEpoch 3/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 0.0014\nEpoch 4/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 4.2375e-04\nEpoch 5/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 3.3236e-04\nEpoch 6/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 1.6652e-04\nEpoch 7/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 3.2670e-04\nEpoch 8/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 6.4188e-05\nEpoch 9/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 8.6045e-04 - val_accuracy: 1.0000 - val_loss: 5.4911e-05\nEpoch 10/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.8223e-04 - val_accuracy: 1.0000 - val_loss: 2.0209e-05\nEpoch 11/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 6.4792e-04 - val_accuracy: 1.0000 - val_loss: 1.5628e-04\nEpoch 12/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 3.6871e-05\nEpoch 13/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0543e-04 - val_accuracy: 1.0000 - val_loss: 3.6848e-05\nEpoch 14/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9562e-04 - val_accuracy: 1.0000 - val_loss: 1.6802e-05\nEpoch 15/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.8242e-05 - val_accuracy: 1.0000 - val_loss: 1.0800e-05\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       spoof       1.00      1.00      1.00       492\n    bonafide       1.00      1.00      1.00       491\n\n    accuracy                           1.00       983\n   macro avg       1.00      1.00      1.00       983\nweighted avg       1.00      1.00      1.00       983\n\nEER: 0.0000 | min t-DCF: 0.0000\n\n🔹 Training for A10 🔹\nEpoch 1/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9271 - loss: 0.2677 - val_accuracy: 0.9949 - val_loss: 0.0313\nEpoch 2/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0403 - val_accuracy: 0.9959 - val_loss: 0.0135\nEpoch 3/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0195 - val_accuracy: 0.9969 - val_loss: 0.0088\nEpoch 4/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0134 - val_accuracy: 0.9975 - val_loss: 0.0065\nEpoch 5/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0100 - val_accuracy: 0.9985 - val_loss: 0.0055\nEpoch 6/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0096 - val_accuracy: 0.9990 - val_loss: 0.0031\nEpoch 7/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0091 - val_accuracy: 0.9990 - val_loss: 0.0031\nEpoch 8/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0077 - val_accuracy: 0.9990 - val_loss: 0.0027\nEpoch 9/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0064 - val_accuracy: 0.9990 - val_loss: 0.0037\nEpoch 10/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0058 - val_accuracy: 0.9995 - val_loss: 0.0021\nEpoch 11/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0050 - val_accuracy: 0.9995 - val_loss: 0.0017\nEpoch 12/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0067 - val_accuracy: 0.9995 - val_loss: 0.0020\nEpoch 13/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0041 - val_accuracy: 0.9990 - val_loss: 0.0028\nEpoch 14/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0043 - val_accuracy: 0.9995 - val_loss: 0.0017\nEpoch 15/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0051 - val_accuracy: 0.9990 - val_loss: 0.0027\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       spoof       1.00      1.00      1.00       492\n    bonafide       1.00      1.00      1.00       491\n\n    accuracy                           1.00       983\n   macro avg       1.00      1.00      1.00       983\nweighted avg       1.00      1.00      1.00       983\n\nEER: 0.0000 | min t-DCF: 0.0000\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"base_path = \"/kaggle/input/mfcc-sid\"\nselected_systems = [\"A11\", \"A12\", \"A13\", \"A14\", \"A15\", \"A16\", \"A17\", \"A18\", \"A19\"]\ndf_bonafide = pd.read_csv(f\"{base_path}/bonafide.csv\")\ndf = load_separate_data(base_path, selected_systems)\n\nfor system_id in df[\"system_id\"].unique():\n    print(f\"\\n🔹 Training for {system_id} 🔹\")\n    \n    df_filtered = df[df[\"system_id\"] == system_id]\n    \n    X_train, y_train, X_dev, y_dev, X_eval, y_eval = prepare_data(df_filtered, df_bonafide)\n\n    model, history = train_and_evaluate(X_train, y_train, X_dev, y_dev, X_eval, y_eval, system_id)\n\n    # plot_training_history(history, system_id)\n    \n    # Free up memory after training\n    del model  \n    K.clear_session()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T03:16:00.767095Z","iopub.execute_input":"2025-03-26T03:16:00.767335Z","execution_failed":"2025-03-26T03:53:56.351Z"}},"outputs":[{"name":"stdout","text":"\n🔹 Training for A11 🔹\nEpoch 1/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9009 - loss: 0.3002 - val_accuracy: 0.9995 - val_loss: 0.0312\nEpoch 2/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0397 - val_accuracy: 1.0000 - val_loss: 0.0088\nEpoch 3/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0132 - val_accuracy: 1.0000 - val_loss: 0.0043\nEpoch 4/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 0.0029\nEpoch 5/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 0.0016\nEpoch 6/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 6.7924e-04\nEpoch 7/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0032\nEpoch 8/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.9522 - val_loss: 0.1258\nEpoch 9/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 5.6912e-04\nEpoch 10/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0018 - val_accuracy: 0.8891 - val_loss: 0.2511\nEpoch 11/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 9.2761e-04 - val_accuracy: 1.0000 - val_loss: 0.0022\nEpoch 12/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.1419e-04 - val_accuracy: 1.0000 - val_loss: 8.4629e-04\nEpoch 13/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.6579e-04 - val_accuracy: 0.9781 - val_loss: 0.0602\nEpoch 14/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 2.2855e-04\nEpoch 15/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 5.4262e-04 - val_accuracy: 1.0000 - val_loss: 3.8055e-04\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       spoof       1.00      1.00      1.00       491\n    bonafide       1.00      1.00      1.00       492\n\n    accuracy                           1.00       983\n   macro avg       1.00      1.00      1.00       983\nweighted avg       1.00      1.00      1.00       983\n\nEER: 0.0000 | min t-DCF: 0.0000\n\n🔹 Training for A12 🔹\nEpoch 1/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8856 - loss: 0.3159 - val_accuracy: 0.9985 - val_loss: 0.0372\nEpoch 2/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0462 - val_accuracy: 0.9995 - val_loss: 0.0107\nEpoch 3/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0192 - val_accuracy: 0.9995 - val_loss: 0.0060\nEpoch 4/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0116 - val_accuracy: 0.9995 - val_loss: 0.0051\nEpoch 5/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0075 - val_accuracy: 0.9995 - val_loss: 0.0043\nEpoch 6/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0050 - val_accuracy: 0.9995 - val_loss: 0.0057\nEpoch 7/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0036 - val_accuracy: 0.9995 - val_loss: 0.0038\nEpoch 8/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.9995 - val_loss: 0.0036\nEpoch 9/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0019 - val_accuracy: 0.9995 - val_loss: 0.0041\nEpoch 10/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 0.9995 - val_loss: 0.0030\nEpoch 11/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.9995 - val_loss: 0.0034\nEpoch 12/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9995 - val_loss: 0.0040\nEpoch 13/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.9995 - val_loss: 0.0037\nEpoch 14/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 9.0999e-04 - val_accuracy: 0.9995 - val_loss: 0.0041\nEpoch 15/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.4076e-04 - val_accuracy: 0.9995 - val_loss: 0.0039\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       spoof       1.00      1.00      1.00       492\n    bonafide       1.00      1.00      1.00       491\n\n    accuracy                           1.00       983\n   macro avg       1.00      1.00      1.00       983\nweighted avg       1.00      1.00      1.00       983\n\nEER: 0.0000 | min t-DCF: 0.0000\n\n🔹 Training for A13 🔹\nEpoch 1/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.9243 - loss: 0.2514 - val_accuracy: 0.9995 - val_loss: 0.0208\nEpoch 2/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0268 - val_accuracy: 0.9995 - val_loss: 0.0064\nEpoch 3/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0116 - val_accuracy: 0.9995 - val_loss: 0.0043\nEpoch 4/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0082 - val_accuracy: 0.9995 - val_loss: 0.0037\nEpoch 5/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0046 - val_accuracy: 0.9995 - val_loss: 0.0024\nEpoch 6/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0048 - val_accuracy: 0.9995 - val_loss: 0.0022\nEpoch 7/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0040 - val_accuracy: 0.9995 - val_loss: 0.0023\nEpoch 8/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0032 - val_accuracy: 0.9995 - val_loss: 0.0018\nEpoch 9/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0035 - val_accuracy: 0.9995 - val_loss: 0.0017\nEpoch 10/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0040 - val_accuracy: 0.9995 - val_loss: 8.5272e-04\nEpoch 11/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.9995 - val_loss: 0.0019\nEpoch 12/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0027 - val_accuracy: 0.9995 - val_loss: 0.0016\nEpoch 13/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 9.4113e-04 - val_accuracy: 0.9995 - val_loss: 0.0022\nEpoch 14/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0031 - val_accuracy: 0.9995 - val_loss: 0.0022\nEpoch 15/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 8.2537e-04 - val_accuracy: 0.9995 - val_loss: 0.0027\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       spoof       1.00      1.00      1.00       492\n    bonafide       1.00      1.00      1.00       491\n\n    accuracy                           1.00       983\n   macro avg       1.00      1.00      1.00       983\nweighted avg       1.00      1.00      1.00       983\n\nEER: 0.0000 | min t-DCF: 0.0000\n\n🔹 Training for A14 🔹\nEpoch 1/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8999 - loss: 0.3130 - val_accuracy: 0.9929 - val_loss: 0.0387\nEpoch 2/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9906 - loss: 0.0485 - val_accuracy: 0.9975 - val_loss: 0.0133\nEpoch 3/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0180 - val_accuracy: 0.9985 - val_loss: 0.0051\nEpoch 4/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0084 - val_accuracy: 0.9985 - val_loss: 0.0044\nEpoch 5/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0057 - val_accuracy: 0.9980 - val_loss: 0.0052\nEpoch 6/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 0.9995 - val_loss: 0.0017\nEpoch 7/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0024 - val_accuracy: 0.9990 - val_loss: 0.0038\nEpoch 8/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 3.2997e-04\nEpoch 9/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0019 - val_accuracy: 0.9990 - val_loss: 0.0022\nEpoch 10/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 5.1873e-04\nEpoch 11/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 7.9721e-04\nEpoch 12/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9990 - val_loss: 0.0021\nEpoch 13/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 3.1016e-04\nEpoch 14/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.3940e-04 - val_accuracy: 1.0000 - val_loss: 2.2874e-04\nEpoch 15/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 6.0500e-04 - val_accuracy: 1.0000 - val_loss: 2.0711e-04\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       spoof       1.00      1.00      1.00       492\n    bonafide       1.00      1.00      1.00       491\n\n    accuracy                           1.00       983\n   macro avg       1.00      1.00      1.00       983\nweighted avg       1.00      1.00      1.00       983\n\nEER: 0.0000 | min t-DCF: 0.0000\n\n🔹 Training for A15 🔹\nEpoch 1/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8987 - loss: 0.2905 - val_accuracy: 0.9980 - val_loss: 0.0273\nEpoch 2/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0390 - val_accuracy: 0.9990 - val_loss: 0.0082\nEpoch 3/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0148 - val_accuracy: 0.9995 - val_loss: 0.0046\nEpoch 4/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0079 - val_accuracy: 0.9995 - val_loss: 0.0023\nEpoch 5/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0061 - val_accuracy: 0.9995 - val_loss: 0.0017\nEpoch 6/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0056 - val_accuracy: 0.9995 - val_loss: 0.0013\nEpoch 7/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0034 - val_accuracy: 0.9995 - val_loss: 0.0013\nEpoch 8/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0027 - val_accuracy: 0.9995 - val_loss: 0.0011\nEpoch 9/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.9995 - val_loss: 7.6164e-04\nEpoch 10/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9995 - val_loss: 0.0011\nEpoch 11/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0019 - val_accuracy: 0.9995 - val_loss: 0.0010\nEpoch 12/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 0.9995 - val_loss: 0.0012\nEpoch 13/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 4.0912e-04\nEpoch 14/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 0.9995 - val_loss: 7.0119e-04\nEpoch 15/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.9995 - val_loss: 0.0010\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       spoof       1.00      1.00      1.00       491\n    bonafide       1.00      1.00      1.00       492\n\n    accuracy                           1.00       983\n   macro avg       1.00      1.00      1.00       983\nweighted avg       1.00      1.00      1.00       983\n\nEER: 0.0000 | min t-DCF: 0.0000\n\n🔹 Training for A16 🔹\nEpoch 1/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.8457 - loss: 0.3802 - val_accuracy: 0.9852 - val_loss: 0.0810\nEpoch 2/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9623 - loss: 0.1264 - val_accuracy: 0.9939 - val_loss: 0.0340\nEpoch 3/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9787 - loss: 0.0688 - val_accuracy: 0.9954 - val_loss: 0.0229\nEpoch 4/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9861 - loss: 0.0453 - val_accuracy: 0.9959 - val_loss: 0.0201\nEpoch 5/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9897 - loss: 0.0360 - val_accuracy: 0.9954 - val_loss: 0.0202\nEpoch 6/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0329 - val_accuracy: 0.9959 - val_loss: 0.0180\nEpoch 7/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0282 - val_accuracy: 0.9954 - val_loss: 0.0176\nEpoch 8/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0246 - val_accuracy: 0.9959 - val_loss: 0.0166\nEpoch 9/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0230 - val_accuracy: 0.9949 - val_loss: 0.0147\nEpoch 10/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0243 - val_accuracy: 0.9949 - val_loss: 0.0147\nEpoch 11/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0190 - val_accuracy: 0.9959 - val_loss: 0.0147\nEpoch 12/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0162 - val_accuracy: 0.9959 - val_loss: 0.0141\nEpoch 13/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0177 - val_accuracy: 0.9954 - val_loss: 0.0134\nEpoch 14/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0178 - val_accuracy: 0.9969 - val_loss: 0.0131\nEpoch 15/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0124 - val_accuracy: 0.9964 - val_loss: 0.0125\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       spoof       1.00      1.00      1.00       492\n    bonafide       1.00      1.00      1.00       491\n\n    accuracy                           1.00       983\n   macro avg       1.00      1.00      1.00       983\nweighted avg       1.00      1.00      1.00       983\n\nEER: 0.0000 | min t-DCF: 0.0000\n\n🔹 Training for A17 🔹\nEpoch 1/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.6796 - loss: 0.5860 - val_accuracy: 0.9710 - val_loss: 0.2046\nEpoch 2/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9004 - loss: 0.2705 - val_accuracy: 0.9771 - val_loss: 0.1050\nEpoch 3/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9360 - loss: 0.1836 - val_accuracy: 0.9898 - val_loss: 0.0604\nEpoch 4/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1299 - val_accuracy: 0.9914 - val_loss: 0.0439\nEpoch 5/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9631 - loss: 0.0985 - val_accuracy: 0.9893 - val_loss: 0.0352\nEpoch 6/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9710 - loss: 0.0776 - val_accuracy: 0.9919 - val_loss: 0.0292\nEpoch 7/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9749 - loss: 0.0669 - val_accuracy: 0.9898 - val_loss: 0.0320\nEpoch 8/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.0811 - val_accuracy: 0.9969 - val_loss: 0.0178\nEpoch 4/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9809 - loss: 0.0558 - val_accuracy: 0.9964 - val_loss: 0.0128\nEpoch 5/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9883 - loss: 0.0397 - val_accuracy: 0.9975 - val_loss: 0.0094\nEpoch 6/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0287 - val_accuracy: 0.9751 - val_loss: 0.0712\nEpoch 7/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0218 - val_accuracy: 0.9985 - val_loss: 0.0048\nEpoch 8/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9932 - loss: 0.0183 - val_accuracy: 0.9995 - val_loss: 0.0042\nEpoch 9/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0125 - val_accuracy: 0.9985 - val_loss: 0.0054\nEpoch 10/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0124 - val_accuracy: 0.9995 - val_loss: 0.0024\nEpoch 11/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0098 - val_accuracy: 0.9995 - val_loss: 0.0016\nEpoch 12/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 0.0014\nEpoch 13/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0045 - val_accuracy: 0.9980 - val_loss: 0.0070\nEpoch 14/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.9985 - val_loss: 0.0052\nEpoch 15/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 9.5634e-04\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       spoof       1.00      1.00      1.00       491\n    bonafide       1.00      1.00      1.00       492\n\n    accuracy                           1.00       983\n   macro avg       1.00      1.00      1.00       983\nweighted avg       1.00      1.00      1.00       983\n\nEER: 0.0000 | min t-DCF: 0.0000\n\n🔹 Training for A19 🔹\nEpoch 1/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.7192 - loss: 0.5419 - val_accuracy: 0.9456 - val_loss: 0.2182\nEpoch 2/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8973 - loss: 0.2769 - val_accuracy: 0.9766 - val_loss: 0.1062\nEpoch 3/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9327 - loss: 0.1829 - val_accuracy: 0.9802 - val_loss: 0.0765\nEpoch 4/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9516 - loss: 0.1309 - val_accuracy: 0.9847 - val_loss: 0.0567\nEpoch 5/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1164 - val_accuracy: 0.9873 - val_loss: 0.0460\nEpoch 6/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.1002 - val_accuracy: 0.9863 - val_loss: 0.0389\nEpoch 7/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9690 - loss: 0.0861 - val_accuracy: 0.9898 - val_loss: 0.0334\nEpoch 8/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9738 - loss: 0.0816 - val_accuracy: 0.9924 - val_loss: 0.0278\nEpoch 9/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9757 - loss: 0.0700 - val_accuracy: 0.9863 - val_loss: 0.0420\nEpoch 10/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9810 - loss: 0.0600 - val_accuracy: 0.9939 - val_loss: 0.0232\nEpoch 11/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.0596 - val_accuracy: 0.9924 - val_loss: 0.0244\nEpoch 12/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9858 - loss: 0.0464 - val_accuracy: 0.9944 - val_loss: 0.0196\nEpoch 13/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.0459 - val_accuracy: 0.9873 - val_loss: 0.0334\nEpoch 14/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9874 - loss: 0.0415 - val_accuracy: 0.9949 - val_loss: 0.0182\nEpoch 15/15\n\u001b[1m1720/1720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9887 - loss: 0.0393 - val_accuracy: 0.9980 - val_loss: 0.0153\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       spoof       1.00      1.00      1.00       492\n    bonafide       1.00      1.00      1.00       491\n\n    accuracy                           1.00       983\n   macro avg       1.00      1.00      1.00       983\nweighted avg       1.00      1.00      1.00       983\n\nEER: 0.0020 | min t-DCF: 0.0224\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}