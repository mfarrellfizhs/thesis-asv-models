{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3842332,"sourceType":"datasetVersion","datasetId":2286778},{"sourceId":10386241,"sourceType":"datasetVersion","datasetId":6393030},{"sourceId":10469024,"sourceType":"datasetVersion","datasetId":6442128}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import subprocess\nfrom ast import literal_eval\n\ndef run(command):\n    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)\n    out, err = process.communicate()\n    print(out.decode('utf-8').strip())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T03:22:44.960711Z","iopub.execute_input":"2025-03-09T03:22:44.961119Z","iopub.status.idle":"2025-03-09T03:22:44.966195Z","shell.execute_reply.started":"2025-03-09T03:22:44.961085Z","shell.execute_reply":"2025-03-09T03:22:44.965118Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('# CPU')\nrun('cat /proc/cpuinfo | egrep -m 1 \"^model name\"')\nrun('cat /proc/cpuinfo | egrep -m 1 \"^cpu MHz\"')\nrun('cat /proc/cpuinfo | egrep -m 1 \"^cpu cores\"')\nprint(\"\")\n\nprint('# RAM')\nrun('cat /proc/meminfo | egrep \"^MemTotal\"')\nprint(\"\")\n\nprint('# OS')\nrun('uname -a')\nprint(\"\")\n\nprint('# GPU')\nrun('lspci | grep VGA')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T03:23:49.398521Z","iopub.execute_input":"2025-03-09T03:23:49.398851Z","iopub.status.idle":"2025-03-09T03:23:49.438015Z","shell.execute_reply.started":"2025-03-09T03:23:49.398824Z","shell.execute_reply":"2025-03-09T03:23:49.437117Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1. Loading the dataset\nthe features are extracted using a slight modification of the actual code provided by [Borzi](https://github.com/UNICT-Fake-Audio/fake-audio-detector)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n# ganti dataset ngikut upload nnti\ntrain = pd.read_csv(\"/kaggle/input/borzi-full/train_set.csv\")\ndev = pd.read_csv(\"/kaggle/input/borzi-full/dev_set.csv\")\neval = pd.read_csv(\"/kaggle/input/borzi-full/eval_set.csv\")\n\n# Ganti value label\ntrain['label'] = train['label'].map({'bonafide': 1, 'spoof': 0})\ndev['label'] = dev['label'].map({'bonafide': 1, 'spoof': 0})\neval['label'] = eval['label'].map({'bonafide': 1, 'spoof': 0})\n\n# Drop col gk penting\ntrain = train.drop('AUDIO_FILE_NAME', axis=1)\ndev = dev.drop('AUDIO_FILE_NAME', axis=1)\neval = eval.drop('AUDIO_FILE_NAME', axis=1)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T12:27:50.460413Z","iopub.execute_input":"2025-03-10T12:27:50.460830Z","iopub.status.idle":"2025-03-10T12:27:54.372416Z","shell.execute_reply.started":"2025-03-10T12:27:50.460773Z","shell.execute_reply":"2025-03-10T12:27:54.371293Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport os\n\n# Concatenate the datasets\ndata = pd.concat([train, dev, eval], axis=0)\n\nnon_feature_columns = ['SYSTEM_ID', 'label', 'spectral_bandwidth']\nfeature_columns = [col for col in data.columns if col not in non_feature_columns]\n\n# Calculate feature variance\nfeature_variances = data[feature_columns].var()\n\n# Identify low-variance features (threshold can be adjusted; using 0.01 here as an example)\nlow_variance_threshold = 0.01\nlow_variance_features = feature_variances[feature_variances < low_variance_threshold]\n\n# Sort SYSTEM_ID before analysis\ndata['SYSTEM_ID'] = pd.Categorical(data['SYSTEM_ID'], categories=sorted(data['SYSTEM_ID'].unique()), ordered=True)\n\n# Plot feature distributions for all features\nfeature_distributions_dir = \"/mnt/data/feature_distributions/\"\nos.makedirs(feature_distributions_dir, exist_ok=True)\n\n# Get a colormap with as many unique colors as there are SYSTEM_IDs\nunique_system_ids = sorted(data['SYSTEM_ID'].unique())\ncolor_map = cm.get_cmap('tab20', len(unique_system_ids))\n\n# Save distribution plots for each feature\nfor feature in feature_columns:\n    plt.figure(figsize=(10, 6))\n    for idx, system_id in enumerate(unique_system_ids):\n        subset = data[data['SYSTEM_ID'] == system_id]\n        plt.hist(subset[feature], bins=30, alpha=0.5, color=color_map(idx), label=f\"SYSTEM_ID: {system_id}\")\n    plt.title(f\"Distribution of {feature}\")\n    plt.xlabel(feature)\n    plt.ylabel(\"Frequency\")\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\n# Return summary of low-variance features\nlow_variance_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-16T13:45:13.112968Z","iopub.execute_input":"2025-01-16T13:45:13.113355Z","iopub.status.idle":"2025-01-16T13:46:34.406832Z","shell.execute_reply.started":"2025-01-16T13:45:13.113301Z","shell.execute_reply":"2025-01-16T13:46:34.405559Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.2 EER calculations","metadata":{"execution":{"iopub.status.busy":"2025-01-14T13:32:41.556095Z","iopub.execute_input":"2025-01-14T13:32:41.556440Z","iopub.status.idle":"2025-01-14T13:32:41.561767Z","shell.execute_reply.started":"2025-01-14T13:32:41.556413Z","shell.execute_reply":"2025-01-14T13:32:41.560473Z"}}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, roc_curve, accuracy_score\ndef eval_metr(y_true, y_pred, P_target=0.5):\n    # Compute ROC curve\n    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n    fnr = 1 - tpr  # False Negative Rate (Miss Rate)\n\n    # Compute EER\n    abs_diff = np.abs(fpr - fnr)\n    eer_index = np.argmin(abs_diff)\n    eer = (fpr[eer_index] + fnr[eer_index]) / 2\n\n    return eer, min_tdcf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T07:59:10.713124Z","iopub.execute_input":"2025-03-19T07:59:10.713632Z","iopub.status.idle":"2025-03-19T07:59:10.722084Z","shell.execute_reply.started":"2025-03-19T07:59:10.713565Z","shell.execute_reply":"2025-03-19T07:59:10.720884Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Model Pipeline","metadata":{}},{"cell_type":"markdown","source":"## 2.1 Random Forest","metadata":{}},{"cell_type":"markdown","source":"### 2.1.1 Singular feature","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom imblearn.over_sampling import SMOTE\ndef random_forest_pipeline(train, dev, eval):\n    excluded_columns = [\"label\", \"duration\", \"size\", \"spectral_bandwidth\"]\n    report_list = []\n    csv_data = []\n\n    # Iterate over all columns except excluded ones\n    for col_name in train.columns:\n        if col_name in excluded_columns:\n            continue\n\n        # Check for NaN values and print a warning if present\n        if train[col_name].isna().any() or dev[col_name].isna().any() or eval[col_name].isna().any():\n            print(f\"Warning: Column '{col_name}' contains NaN values. Filling with mean.\")\n\n        # Step 1: Extract X_set and y_set from train, dev, and eval datasets\n        X_train, y_train = train[[col_name]].fillna(train[col_name].mean()), train['label']\n        X_dev, y_dev = dev[[col_name]].fillna(dev[col_name].mean()), dev['label']\n        X_eval, y_eval = eval[[col_name]].fillna(eval[col_name].mean()), eval['label']\n\n        # Step 2: Apply SMOTE to balance the training data\n        smote = SMOTE(random_state=42)\n        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\n        # Step 3: Create and train the Random Forest model\n        rf_model = RandomForestClassifier(random_state=42)\n        rf_model.fit(X_train_smote, y_train_smote)\n\n        # Step 4: Evaluate on dev set\n        y_dev_pred = rf_model.predict(X_dev)\n        y_dev_prob = rf_model.predict_proba(X_dev)[:, 1]\n        accuracy_dev = accuracy_score(y_dev, y_dev_pred)\n        eer_dev, tdcf_dev = eval_metr(y_dev, y_dev_prob, 0.1588, 2.1007)\n        dev_report = classification_report(y_dev, y_dev_pred)\n    \n        # Step 5: Evaluate on eval set\n        y_eval_pred = rf_model.predict(X_eval)\n        y_eval_prob = rf_model.predict_proba(X_eval)[:, 1]\n        accuracy_eval = accuracy_score(y_eval, y_eval_pred)\n        eer_eval, tdcf_eval = eval_metr(y_eval, y_eval_prob, 0.1847, 2.0173)\n        eval_report = classification_report(y_eval, y_eval_pred)\n\n        # Step 6: Store the results in the text report\n        report_list.append(f\"=== Evaluation for Feature: {col_name} ===\\n\")\n        report_list.append(\"\\n=== Evaluation on Dev Set ===\")\n        report_list.append(f\"Accuracy: {accuracy_dev:.4f}\")\n        report_list.append(\"Classification Report:\")\n        report_list.append(dev_report)\n        report_list.append(\"Custom Eval Metric:\")\n        report_list.append(f\"EER on validation data: {eer_dev * 100:.2f}%\")\n        report_list.append(f\"Min t-DCF on validation data: {tdcf_dev:.4f}\\n\")\n\n        report_list.append(\"\\n=== Evaluation on Eval Set ===\")\n        report_list.append(f\"Accuracy: {accuracy_eval:.4f}\")\n        report_list.append(\"Classification Report:\")\n        report_list.append(eval_report)\n        report_list.append(\"Custom Eval Metric:\")\n        report_list.append(f\"EER on testing data: {eer_eval * 100:.2f}%\")\n        report_list.append(f\"Min t-DCF on testing data: {tdcf_eval:.4f}\\n\\n\")\n\n        # Step 7: Store the results in the CSV data\n        csv_data.append({\n            \"Feature\": col_name,\n            \"Dev Accuracy\": accuracy_dev,\n            \"Dev EER\": eer_dev * 100,\n            \"Dev Min t-DCF\": tdcf_dev,\n            \"Eval Accuracy\": accuracy_eval,\n            \"Eval EER\": eer_eval * 100,\n            \"Eval Min t-DCF\": tdcf_eval\n        })\n\n    # Step 8: Save the detailed report to a text file\n    with open('rf_evaluation_report.txt', 'w') as f:\n        f.writelines(\"\\n\".join(report_list))\n\n    # Step 9: Save the CSV data to a file\n    df_csv = pd.DataFrame(csv_data)\n    df_csv.to_csv('rf_evaluation_metrics.csv', index=False)\n\n    print(\"Detailed evaluation report saved to rf_evaluation_report.txt\")\n    print(\"Summary metrics saved to rf_evaluation_metrics.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:13:53.114359Z","iopub.execute_input":"2025-01-08T07:13:53.114958Z","iopub.status.idle":"2025-01-08T07:13:53.967298Z","shell.execute_reply.started":"2025-01-08T07:13:53.114922Z","shell.execute_reply":"2025-01-08T07:13:53.966015Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"random_forest_pipeline(train, dev, eval)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:13:54.979806Z","iopub.execute_input":"2025-01-08T07:13:54.980325Z","iopub.status.idle":"2025-01-08T07:18:03.052198Z","shell.execute_reply.started":"2025-01-08T07:13:54.980294Z","shell.execute_reply":"2025-01-08T07:18:03.050840Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2.1.2 All Feature","metadata":{}},{"cell_type":"code","source":"import joblib\nfrom sklearn.ensemble import RandomForestClassifier\nfrom imblearn.over_sampling import SMOTE\ndef random_forest_pipeline_all(train, dev, eval, excluded_columns):\n    # Step 1: Prepare the data\n    feature_columns = [col for col in train.columns if col not in excluded_columns]\n    \n    # Function to impute NaN values with column mean\n    def impute_missing_values(df, feature_columns):\n        for col in feature_columns:\n            if df[col].isna().any():\n                print(f\"Column '{col}' contains NaN values. Filling with mean.\")\n                df[col].fillna(df[col].mean(), inplace=True)\n        return df\n    \n    # Impute missing values in train, dev, and eval datasets\n    train = impute_missing_values(train, feature_columns)\n    dev = impute_missing_values(dev, feature_columns)\n    eval = impute_missing_values(eval, feature_columns)\n\n    # Separate features and target\n    X_train, y_train = train[feature_columns], train['label']\n    X_dev, y_dev = dev[feature_columns], dev['label']\n    X_eval, y_eval = eval[feature_columns], eval['label']\n\n    # Step 2: Apply SMOTE to balance the training data\n    smote = SMOTE(random_state=42)\n    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\n    # Step 3: Create and train the Random Forest model\n    rf_model = RandomForestClassifier(random_state=42)\n    rf_model.fit(X_train_smote, y_train_smote)\n\n    # Step 4: Evaluate on dev set\n    y_dev_pred = rf_model.predict(X_dev)\n    y_dev_prob = rf_model.predict_proba(X_dev)[:, 1]\n    accuracy_dev = accuracy_score(y_dev, y_dev_pred)\n    eer_dev, tdcf_dev = eval_metr(y_dev, y_dev_prob, 0.1588, 2.1007)\n    dev_report = classification_report(y_dev, y_dev_pred)\n    \n    # Step 5: Evaluate on eval set\n    y_eval_pred = rf_model.predict(X_eval)\n    y_eval_prob = rf_model.predict_proba(X_eval)[:, 1]\n    accuracy_eval = accuracy_score(y_eval, y_eval_pred)\n    eer_eval, tdcf_eval = eval_metr(y_eval, y_eval_prob, 0.1847, 2.0173)\n    eval_report = classification_report(y_eval, y_eval_pred)\n\n    # Step 6: Print out the results\n    print(\"\\n=== Evaluation on Dev Set ===\")\n    print(f\"Accuracy: {accuracy_dev:.4f}\")\n    print(\"Classification Report:\")\n    print(dev_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on validation data: {eer_dev * 100:.2f}%\")\n    print(f\"Min t-DCF on validation data: {tdcf_dev:.4f}\")\n\n    print(\"\\n=== Evaluation on Eval Set ===\")\n    print(f\"Accuracy: {accuracy_eval:.4f}\")\n    print(\"Classification Report:\")\n    print(eval_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on testing data: {eer_eval * 100:.2f}%\")\n    print(f\"Min t-DCF on testing data: {tdcf_eval:.4f}\")\n\n    # Step 7: Save the trained model\n    joblib.dump(rf_model, 'random_forest_model.pkl')\n    print(\"Random Forest model saved as random_forest_model.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T07:53:38.123157Z","iopub.execute_input":"2025-01-26T07:53:38.123533Z","iopub.status.idle":"2025-01-26T07:53:38.739615Z","shell.execute_reply.started":"2025-01-26T07:53:38.123506Z","shell.execute_reply":"2025-01-26T07:53:38.738536Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"excluded_columns = [\"label\", \"duration\", \"size\", \"spectral_bandwidth\"]\n# Assume `data` is a DataFrame that includes features and a 'label' column\nrandom_forest_pipeline_all(train, dev, eval, excluded_columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:18:03.070714Z","iopub.execute_input":"2025-01-08T07:18:03.071263Z","iopub.status.idle":"2025-01-08T07:18:23.822957Z","shell.execute_reply.started":"2025-01-08T07:18:03.071223Z","shell.execute_reply":"2025-01-08T07:18:23.821816Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.2 AdaBoost","metadata":{}},{"cell_type":"markdown","source":"### 2.2.1 Singular Features","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom imblearn.over_sampling import SMOTE\ndef adaboost_pipeline(train, dev, eval):\n    excluded_columns = [\"label\", \"duration\", \"size\", \"spectral_bandwidth\"]\n    report_list = []\n    csv_data = []\n\n    # Iterate over all columns except excluded ones\n    for col_name in train.columns:\n        if col_name in excluded_columns:\n            continue\n\n        # Check for NaN values and print a warning if present\n        if train[col_name].isna().any() or dev[col_name].isna().any() or eval[col_name].isna().any():\n            print(f\"Warning: Column '{col_name}' contains NaN values. Filling with mean.\")\n\n        # Step 1: Extract X_set and y_set from train, dev, and eval datasets\n        X_train, y_train = train[[col_name]].fillna(train[col_name].mean()), train['label']\n        X_dev, y_dev = dev[[col_name]].fillna(dev[col_name].mean()), dev['label']\n        X_eval, y_eval = eval[[col_name]].fillna(eval[col_name].mean()), eval['label']\n\n        # Step 2: Apply SMOTE to balance the training data\n        smote = SMOTE(random_state=42)\n        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\n        # Step 3: Create and train the Random Forest model\n        ada_model = AdaBoostClassifier(random_state=42)\n        ada_model.fit(X_train_smote, y_train_smote)\n\n        # Step 4: Evaluate on dev set\n        y_dev_pred = ada_model.predict(X_dev)\n        y_dev_prob = ada_model.predict_proba(X_dev)[:, 1]\n        accuracy_dev = accuracy_score(y_dev, y_dev_pred)\n        eer_dev, tdcf_dev = eval_metr(y_dev, y_dev_prob, 0.1588, 2.1007)\n        dev_report = classification_report(y_dev, y_dev_pred)\n    \n        # Step 5: Evaluate on eval set\n        y_eval_pred = ada_model.predict(X_eval)\n        y_eval_prob = ada_model.predict_proba(X_eval)[:, 1]\n        accuracy_eval = accuracy_score(y_eval, y_eval_pred)\n        eer_eval, tdcf_eval = eval_metr(y_eval, y_eval_prob, 0.1847, 2.0173)\n        eval_report = classification_report(y_eval, y_eval_pred)\n\n        # Step 6: Store the results in the text report\n        report_list.append(f\"=== Evaluation for Feature: {col_name} ===\\n\")\n        report_list.append(\"\\n=== Evaluation on Dev Set ===\")\n        report_list.append(f\"Accuracy: {accuracy_dev:.4f}\")\n        report_list.append(\"Classification Report:\")\n        report_list.append(dev_report)\n        report_list.append(\"Custom Eval Metric:\")\n        report_list.append(f\"EER on validation data: {eer_dev * 100:.2f}%\")\n        report_list.append(f\"Min t-DCF on validation data: {tdcf_dev:.4f}\\n\")\n\n        report_list.append(\"\\n=== Evaluation on Eval Set ===\")\n        report_list.append(f\"Accuracy: {accuracy_eval:.4f}\")\n        report_list.append(\"Classification Report:\")\n        report_list.append(eval_report)\n        report_list.append(\"Custom Eval Metric:\")\n        report_list.append(f\"EER on testing data: {eer_eval * 100:.2f}%\")\n        report_list.append(f\"Min t-DCF on testing data: {tdcf_eval:.4f}\\n\\n\")\n\n        # Step 7: Store the results in the CSV data\n        csv_data.append({\n            \"Feature\": col_name,\n            \"Dev Accuracy\": accuracy_dev,\n            \"Dev EER\": eer_dev * 100,\n            \"Dev Min t-DCF\": tdcf_dev,\n            \"Eval Accuracy\": accuracy_eval,\n            \"Eval EER\": eer_eval * 100,\n            \"Eval Min t-DCF\": tdcf_eval\n        })\n\n    # Step 8: Save the detailed report to a text file\n    with open('ada_evaluation_report.txt', 'w') as f:\n        f.writelines(\"\\n\".join(report_list))\n\n    # Step 9: Save the CSV data to a file\n    df_csv = pd.DataFrame(csv_data)\n    df_csv.to_csv('ada_evaluation_metrics.csv', index=False)\n\n    print(\"Detailed evaluation report saved to ada_evaluation_report.txt\")\n    print(\"Summary metrics saved to ada_evaluation_metrics.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:18:23.824773Z","iopub.execute_input":"2025-01-08T07:18:23.825095Z","iopub.status.idle":"2025-01-08T07:18:23.838807Z","shell.execute_reply.started":"2025-01-08T07:18:23.825068Z","shell.execute_reply":"2025-01-08T07:18:23.837247Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"adaboost_pipeline(train, dev, eval)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:18:23.839973Z","iopub.execute_input":"2025-01-08T07:18:23.840296Z","iopub.status.idle":"2025-01-08T07:19:49.499560Z","shell.execute_reply.started":"2025-01-08T07:18:23.840269Z","shell.execute_reply":"2025-01-08T07:19:49.498344Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2.2.2 All Features","metadata":{}},{"cell_type":"code","source":"import joblib\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom imblearn.over_sampling import SMOTE\ndef adaboost_pipeline_all(train, dev, eval, excluded_columns):\n    # Step 1: Prepare the data\n    feature_columns = [col for col in train.columns if col not in excluded_columns]\n    \n    # Function to impute NaN values with column mean\n    def impute_missing_values(df, feature_columns):\n        for col in feature_columns:\n            if df[col].isna().any():\n                print(f\"Column '{col}' contains NaN values. Filling with mean.\")\n                df[col].fillna(df[col].mean(), inplace=True)\n        return df\n    \n    # Impute missing values in train, dev, and eval datasets\n    train = impute_missing_values(train, feature_columns)\n    dev = impute_missing_values(dev, feature_columns)\n    eval = impute_missing_values(eval, feature_columns)\n\n    # Separate features and target\n    X_train, y_train = train[feature_columns], train['label']\n    X_dev, y_dev = dev[feature_columns], dev['label']\n    X_eval, y_eval = eval[feature_columns], eval['label']\n\n    # Step 1: Apply SMOTE to balance the training data\n    smote = SMOTE(random_state=42)\n    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\n    # Step 2: Create and train the Random Forest model\n    ada_model = AdaBoostClassifier(random_state=42)\n    ada_model.fit(X_train_smote, y_train_smote)\n\n    # Step 3: Evaluate on dev set\n    y_dev_pred = ada_model.predict(X_dev)\n    y_dev_prob = ada_model.predict_proba(X_dev)[:, 1]\n    accuracy_dev = accuracy_score(y_dev, y_dev_pred)\n    eer_dev, tdcf_dev = eval_metr(y_dev, y_dev_prob, 0.1588, 2.1007)\n    dev_report = classification_report(y_dev, y_dev_pred)\n\n    # Step 4: Evaluate on eval set\n    y_eval_pred = ada_model.predict(X_eval)\n    y_eval_prob = ada_model.predict_proba(X_eval)[:, 1]\n    accuracy_eval = accuracy_score(y_eval, y_eval_pred)\n    eer_eval, tdcf_eval = eval_metr(y_eval, y_eval_prob, 0.1847, 2.0173)\n    eval_report = classification_report(y_eval, y_eval_pred)\n\n    # Step 5: Print out the results\n    print(\"\\n=== Evaluation on Dev Set ===\")\n    print(f\"Accuracy: {accuracy_dev:.4f}\")\n    print(\"Classification Report:\")\n    print(dev_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on validation data: {eer_dev * 100:.2f}%\")\n    print(f\"Min t-DCF on validation data: {tdcf_dev:.4f}\")\n\n    print(\"\\n=== Evaluation on Eval Set ===\")\n    print(f\"Accuracy: {accuracy_eval:.4f}\")\n    print(\"Classification Report:\")\n    print(eval_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on testing data: {eer_eval * 100:.2f}%\")\n    print(f\"Min t-DCF on testing data: {tdcf_eval:.4f}\")\n\n    # Step 6: Save the trained model\n    joblib.dump(ada_model, 'adaboost_model.pkl')\n    print(\"adaboost model saved as adaboost_model.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T07:53:45.474648Z","iopub.execute_input":"2025-01-26T07:53:45.475183Z","iopub.status.idle":"2025-01-26T07:53:45.485180Z","shell.execute_reply.started":"2025-01-26T07:53:45.475151Z","shell.execute_reply":"2025-01-26T07:53:45.484114Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"excluded_columns = [\"label\", \"duration\", \"size\", \"spectral_bandwidth\"]\nadaboost_pipeline_all(train, dev, eval, excluded_columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:19:49.515249Z","iopub.execute_input":"2025-01-08T07:19:49.515674Z","iopub.status.idle":"2025-01-08T07:20:02.399548Z","shell.execute_reply.started":"2025-01-08T07:19:49.515639Z","shell.execute_reply":"2025-01-08T07:20:02.397843Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.3 XGBoost","metadata":{}},{"cell_type":"markdown","source":"### 2.3.1 Singular Features","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom imblearn.over_sampling import SMOTE\ndef xgboost_pipeline(train, dev, eval):\n    excluded_columns = [\"label\", \"duration\", \"size\", \"spectral_bandwidth\"]\n    report_list = []\n    csv_data = []\n\n    # Iterate over all columns except excluded ones\n    for col_name in train.columns:\n        if col_name in excluded_columns:\n            continue\n\n        # Check for NaN values and print a warning if present\n        if train[col_name].isna().any() or dev[col_name].isna().any() or eval[col_name].isna().any():\n            print(f\"Warning: Column '{col_name}' contains NaN values. Filling with mean.\")\n\n        # Step 1: Extract X_set and y_set from train, dev, and eval datasets\n        X_train, y_train = train[[col_name]].fillna(train[col_name].mean()), train['label']\n        X_dev, y_dev = dev[[col_name]].fillna(dev[col_name].mean()), dev['label']\n        X_eval, y_eval = eval[[col_name]].fillna(eval[col_name].mean()), eval['label']\n\n        # Step 2: Apply SMOTE to balance the training data\n        smote = SMOTE(random_state=42)\n        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\n        # Step 3: Create and train the Random Forest model\n        xgb_model = AdaBoostClassifier(random_state=42)\n        xgb_model.fit(X_train_smote, y_train_smote)\n\n        # Step 4: Evaluate on dev set\n        y_dev_pred = xgb_model.predict(X_dev)\n        y_dev_prob = xgb_model.predict_proba(X_dev)[:, 1]\n        accuracy_dev = accuracy_score(y_dev, y_dev_pred)\n        eer_dev, tdcf_dev = eval_metr(y_dev, y_dev_prob, 0.1588, 2.1007)\n        dev_report = classification_report(y_dev, y_dev_pred)\n    \n        # Step 5: Evaluate on eval set\n        y_eval_pred = xgb_model.predict(X_eval)\n        y_eval_prob = xgb_model.predict_proba(X_eval)[:, 1]\n        accuracy_eval = accuracy_score(y_eval, y_eval_pred)\n        eer_eval, tdcf_eval = eval_metr(y_eval, y_eval_prob, 0.1847, 2.0173)\n        eval_report = classification_report(y_eval, y_eval_pred)\n\n        # Step 6: Store the results in the text report\n        report_list.append(f\"=== Evaluation for Feature: {col_name} ===\\n\")\n        report_list.append(\"\\n=== Evaluation on Dev Set ===\")\n        report_list.append(f\"Accuracy: {accuracy_dev:.4f}\")\n        report_list.append(\"Classification Report:\")\n        report_list.append(dev_report)\n        report_list.append(\"Custom Eval Metric:\")\n        report_list.append(f\"EER on validation data: {eer_dev * 100:.2f}%\")\n        report_list.append(f\"Min t-DCF on validation data: {tdcf_dev:.4f}\\n\")\n\n        report_list.append(\"\\n=== Evaluation on Eval Set ===\")\n        report_list.append(f\"Accuracy: {accuracy_eval:.4f}\")\n        report_list.append(\"Classification Report:\")\n        report_list.append(eval_report)\n        report_list.append(\"Custom Eval Metric:\")\n        report_list.append(f\"EER on testing data: {eer_eval * 100:.2f}%\")\n        report_list.append(f\"Min t-DCF on testing data: {tdcf_eval:.4f}\\n\\n\")\n\n        # Step 7: Store the results in the CSV data\n        csv_data.append({\n            \"Feature\": col_name,\n            \"Dev Accuracy\": accuracy_dev,\n            \"Dev EER\": eer_dev * 100,\n            \"Dev Min t-DCF\": tdcf_dev,\n            \"Eval Accuracy\": accuracy_eval,\n            \"Eval EER\": eer_eval * 100,\n            \"Eval Min t-DCF\": tdcf_eval\n        })\n\n    # Step 8: Save the detailed report to a text file\n    with open('xgb_evaluation_report.txt', 'w') as f:\n        f.writelines(\"\\n\".join(report_list))\n\n    # Step 9: Save the CSV data to a file\n    df_csv = pd.DataFrame(csv_data)\n    df_csv.to_csv('xgb_evaluation_metrics.csv', index=False)\n\n    print(\"Detailed evaluation report saved to xgb_evaluation_report.txt\")\n    print(\"Summary metrics saved to xgb_evaluation_metrics.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:20:55.545425Z","iopub.execute_input":"2025-01-08T07:20:55.545861Z","iopub.status.idle":"2025-01-08T07:20:55.558906Z","shell.execute_reply.started":"2025-01-08T07:20:55.545825Z","shell.execute_reply":"2025-01-08T07:20:55.557494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgboost_pipeline(train, dev, eval)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:20:58.280488Z","iopub.execute_input":"2025-01-08T07:20:58.280870Z","iopub.status.idle":"2025-01-08T07:22:24.095065Z","shell.execute_reply.started":"2025-01-08T07:20:58.280839Z","shell.execute_reply":"2025-01-08T07:22:24.093581Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2.3.2 All Features","metadata":{}},{"cell_type":"code","source":"import joblib\nfrom xgboost import XGBClassifier\nfrom imblearn.over_sampling import SMOTE\ndef xgboost_pipeline_all(train, dev, eval, excluded_columns):\n    # Step 1: Prepare the data\n    feature_columns = [col for col in train.columns if col not in excluded_columns]\n    \n    # Function to impute NaN values with column mean\n    def impute_missing_values(df, feature_columns):\n        for col in feature_columns:\n            if df[col].isna().any():\n                print(f\"Column '{col}' contains NaN values. Filling with mean.\")\n                df[col].fillna(df[col].mean(), inplace=True)\n        return df\n    \n    # Impute missing values in train, dev, and eval datasets\n    train = impute_missing_values(train, feature_columns)\n    dev = impute_missing_values(dev, feature_columns)\n    eval = impute_missing_values(eval, feature_columns)\n\n    # Separate features and target\n    X_train, y_train = train[feature_columns], train['label']\n    X_dev, y_dev = dev[feature_columns], dev['label']\n    X_eval, y_eval = eval[feature_columns], eval['label']\n\n    # Step 1: Apply SMOTE to balance the training data\n    smote = SMOTE(random_state=42)\n    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\n    # Step 2: Create and train the Random Forest model\n    xgb_model = XGBClassifier(random_state=42)\n    xgb_model.fit(X_train_smote, y_train_smote)\n\n    # Step 3: Evaluate on dev set\n    y_dev_pred = xgb_model.predict(X_dev)\n    y_dev_prob = xgb_model.predict_proba(X_dev)[:, 1]\n    accuracy_dev = accuracy_score(y_dev, y_dev_pred)\n    dev_report = classification_report(y_dev, y_dev_pred)\n    eer_dev, tdcf_dev = eval_metr(y_dev, y_dev_prob, 0.1588, 2.1007)\n\n    # Step 4: Evaluate on eval set\n    y_eval_pred = xgb_model.predict(X_eval)\n    y_eval_prob = xgb_model.predict_proba(X_eval)[:, 1]\n    accuracy_eval = accuracy_score(y_eval, y_eval_pred)\n    eval_report = classification_report(y_eval, y_eval_pred)\n    eer_eval, tdcf_eval = eval_metr(y_eval, y_eval_prob, 0.1847, 2.0173)\n\n    # Step 5: Print out the results\n    print(\"\\n=== Evaluation on Dev Set ===\")\n    print(f\"Accuracy: {accuracy_dev:.4f}\")\n    print(\"Classification Report:\")\n    print(dev_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on validation data: {eer_dev * 100:.2f}%\")\n    print(f\"Min t-DCF on validation data: {tdcf_dev:.4f}\")\n\n    print(\"\\n=== Evaluation on Eval Set ===\")\n    print(f\"Accuracy: {accuracy_eval:.4f}\")\n    print(\"Classification Report:\")\n    print(eval_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on testing data: {eer_eval * 100:.2f}%\")\n    print(f\"Min t-DCF on testing data: {tdcf_eval:.4f}\")\n\n    # Step 6: Save the trained model\n    joblib.dump(xgb_model, 'xgboost_model.pkl')\n    print(\"xgboost model saved as xgboost_model.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T07:53:48.638226Z","iopub.execute_input":"2025-01-26T07:53:48.638616Z","iopub.status.idle":"2025-01-26T07:53:48.874553Z","shell.execute_reply.started":"2025-01-26T07:53:48.638557Z","shell.execute_reply":"2025-01-26T07:53:48.873680Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"excluded_columns = [\"label\", \"duration\", \"size\", \"spectral_bandwidth\"]\nxgboost_pipeline_all(train, dev, eval, excluded_columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T07:22:24.111984Z","iopub.execute_input":"2025-01-08T07:22:24.112405Z","iopub.status.idle":"2025-01-08T07:22:25.807610Z","shell.execute_reply.started":"2025-01-08T07:22:24.112370Z","shell.execute_reply":"2025-01-08T07:22:25.806676Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Preselect Features","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Feature initialization","metadata":{}},{"cell_type":"code","source":"def filter_features(train, dev, eval):\n    SELECT_FEATURES = ['bit_rate', 'lfcc', 'mindom', 'size', 'spectral_flatness', 'spectral_centroid', 'spectral_mean', 'spectral_rms', 'spectral_spread']\n\n    # Step 1: Select only the columns in SELECT_FEATURES plus 'label'\n    selected_columns = SELECT_FEATURES + ['label']\n\n    # Filter the datasets to include only the selected columns\n    train_filtered = train[selected_columns]\n    dev_filtered = dev[selected_columns]\n    eval_filtered = eval[selected_columns]\n\n    return train_filtered, dev_filtered, eval_filtered\n\ntrain_filtered, dev_filtered, eval_filtered = filter_features(train, dev, eval)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T08:13:30.529154Z","iopub.execute_input":"2025-01-08T08:13:30.529479Z","iopub.status.idle":"2025-01-08T08:13:30.541907Z","shell.execute_reply.started":"2025-01-08T08:13:30.529454Z","shell.execute_reply":"2025-01-08T08:13:30.540664Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.2 Random Forest","metadata":{}},{"cell_type":"code","source":"import joblib\nfrom sklearn.ensemble import RandomForestClassifier\nfrom imblearn.over_sampling import SMOTE\ndef rf_pipeline_select(train, dev, eval):\n    # Step 1: Prepare the data\n    feature_columns = [col for col in train.columns if col != 'label']\n    \n    # Function to impute NaN values with column mean\n    def impute_missing_values(df, feature_columns):\n        for col in feature_columns:\n            if df[col].isna().any():\n                print(f\"Column '{col}' contains NaN values. Filling with mean.\")\n                df[col].fillna(df[col].mean(), inplace=True)\n        return df\n    \n    # Impute missing values in train, dev, and eval datasets\n    train = impute_missing_values(train, feature_columns)\n    dev = impute_missing_values(dev, feature_columns)\n    eval = impute_missing_values(eval, feature_columns)\n\n    # Separate features and target\n    X_train, y_train = train[feature_columns], train['label']\n    X_dev, y_dev = dev[feature_columns], dev['label']\n    X_eval, y_eval = eval[feature_columns], eval['label']\n\n    # Step 2: Apply SMOTE to balance the training data\n    smote = SMOTE(random_state=42)\n    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\n    # Step 3: Create and train the Random Forest model\n    rf_model = RandomForestClassifier(random_state=42)\n    rf_model.fit(X_train_smote, y_train_smote)\n\n    # Step 4: Evaluate on dev set\n    y_dev_pred = rf_model.predict(X_dev)\n    y_dev_prob = rf_model.predict_proba(X_dev)[:, 1]\n    accuracy_dev = accuracy_score(y_dev, y_dev_pred)\n    eer_dev, tdcf_dev = eval_metr(y_dev, y_dev_prob, 0.1588, 2.1007)\n    dev_report = classification_report(y_dev, y_dev_pred)\n    \n    # Step 5: Evaluate on eval set\n    y_eval_pred = rf_model.predict(X_eval)\n    y_eval_prob = rf_model.predict_proba(X_eval)[:, 1]\n    accuracy_eval = accuracy_score(y_eval, y_eval_pred)\n    eer_eval, tdcf_eval = eval_metr(y_eval, y_eval_prob, 0.1847, 2.0173)\n    eval_report = classification_report(y_eval, y_eval_pred)\n\n    # Step 6: Print out the results\n    print(\"\\n=== Evaluation on Dev Set ===\")\n    print(f\"Accuracy: {accuracy_dev:.4f}\")\n    print(\"Classification Report:\")\n    print(dev_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on validation data: {eer_dev * 100:.2f}%\")\n    print(f\"Min t-DCF on validation data: {tdcf_dev:.4f}\")\n\n    print(\"\\n=== Evaluation on Eval Set ===\")\n    print(f\"Accuracy: {accuracy_eval:.4f}\")\n    print(\"Classification Report:\")\n    print(eval_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on testing data: {eer_eval * 100:.2f}%\")\n    print(f\"Min t-DCF on testing data: {tdcf_eval:.4f}\")\n\n    # Step 7: Save the trained model\n    joblib.dump(rf_model, 'rf_select_model.pkl')\n    print(\"Random Forest model saved as rf_select_model.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T08:13:34.106491Z","iopub.execute_input":"2025-01-08T08:13:34.106919Z","iopub.status.idle":"2025-01-08T08:13:34.118152Z","shell.execute_reply.started":"2025-01-08T08:13:34.106889Z","shell.execute_reply":"2025-01-08T08:13:34.116801Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rf_pipeline_select(train_filtered, dev_filtered, eval_filtered)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T08:13:34.630780Z","iopub.execute_input":"2025-01-08T08:13:34.631110Z","iopub.status.idle":"2025-01-08T08:13:50.798739Z","shell.execute_reply.started":"2025-01-08T08:13:34.631084Z","shell.execute_reply":"2025-01-08T08:13:50.797608Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.3 AdaBoost","metadata":{}},{"cell_type":"code","source":"import joblib\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom imblearn.over_sampling import SMOTE\ndef ada_pipeline_select(train, dev, eval):\n    # Step 1: Prepare the data\n    feature_columns = [col for col in train.columns if col != 'label']\n    \n    # Function to impute NaN values with column mean\n    def impute_missing_values(df, feature_columns):\n        for col in feature_columns:\n            if df[col].isna().any():\n                print(f\"Column '{col}' contains NaN values. Filling with mean.\")\n                df[col].fillna(df[col].mean(), inplace=True)\n        return df\n    \n    # Impute missing values in train, dev, and eval datasets\n    train = impute_missing_values(train, feature_columns)\n    dev = impute_missing_values(dev, feature_columns)\n    eval = impute_missing_values(eval, feature_columns)\n\n    # Separate features and target\n    X_train, y_train = train[feature_columns], train['label']\n    X_dev, y_dev = dev[feature_columns], dev['label']\n    X_eval, y_eval = eval[feature_columns], eval['label']\n\n    # Step 2: Apply SMOTE to balance the training data\n    smote = SMOTE(random_state=42)\n    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\n    # Step 3: Create and train the Random Forest model\n    ada_model = AdaBoostClassifier(random_state=42)\n    ada_model.fit(X_train_smote, y_train_smote)\n\n    # Step 4: Evaluate on dev set\n    y_dev_pred = ada_model.predict(X_dev)\n    y_dev_prob = ada_model.predict_proba(X_dev)[:, 1]\n    accuracy_dev = accuracy_score(y_dev, y_dev_pred)\n    eer_dev, tdcf_dev = eval_metr(y_dev, y_dev_prob, 0.1588, 2.1007)\n    dev_report = classification_report(y_dev, y_dev_pred)\n    \n    # Step 5: Evaluate on eval set\n    y_eval_pred = ada_model.predict(X_eval)\n    y_eval_prob = ada_model.predict_proba(X_eval)[:, 1]\n    accuracy_eval = accuracy_score(y_eval, y_eval_pred)\n    eer_eval, tdcf_eval = eval_metr(y_eval, y_eval_prob, 0.1847, 2.0173)\n    eval_report = classification_report(y_eval, y_eval_pred)\n\n    # Step 6: Print out the results\n    print(\"\\n=== Evaluation on Dev Set ===\")\n    print(f\"Accuracy: {accuracy_dev:.4f}\")\n    print(\"Classification Report:\")\n    print(dev_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on validation data: {eer_dev * 100:.2f}%\")\n    print(f\"Min t-DCF on validation data: {tdcf_dev:.4f}\")\n\n    print(\"\\n=== Evaluation on Eval Set ===\")\n    print(f\"Accuracy: {accuracy_eval:.4f}\")\n    print(\"Classification Report:\")\n    print(eval_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on testing data: {eer_eval * 100:.2f}%\")\n    print(f\"Min t-DCF on testing data: {tdcf_eval:.4f}\")\n\n    # Step 7: Save the trained model\n    joblib.dump(ada_model, 'ada_select_model.pkl')\n    print(\"Adaboost model saved as ada_select_model.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T08:13:50.800277Z","iopub.execute_input":"2025-01-08T08:13:50.800615Z","iopub.status.idle":"2025-01-08T08:13:50.811610Z","shell.execute_reply.started":"2025-01-08T08:13:50.800584Z","shell.execute_reply":"2025-01-08T08:13:50.810562Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ada_pipeline_select(train_filtered, dev_filtered, eval_filtered)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T08:13:50.813445Z","iopub.execute_input":"2025-01-08T08:13:50.813791Z","iopub.status.idle":"2025-01-08T08:13:55.227024Z","shell.execute_reply.started":"2025-01-08T08:13:50.813763Z","shell.execute_reply":"2025-01-08T08:13:55.226006Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.4 XGBoost","metadata":{}},{"cell_type":"code","source":"import joblib\nfrom xgboost import XGBClassifier\nfrom imblearn.over_sampling import SMOTE\ndef xgb_pipeline_select(train, dev, eval):\n    # Step 1: Prepare the data\n    feature_columns = [col for col in train.columns if col != 'label']\n    \n    # Function to impute NaN values with column mean\n    def impute_missing_values(df, feature_columns):\n        for col in feature_columns:\n            if df[col].isna().any():\n                print(f\"Column '{col}' contains NaN values. Filling with mean.\")\n                df[col].fillna(df[col].mean(), inplace=True)\n        return df\n    \n    # Impute missing values in train, dev, and eval datasets\n    train = impute_missing_values(train, feature_columns)\n    dev = impute_missing_values(dev, feature_columns)\n    eval = impute_missing_values(eval, feature_columns)\n\n    # Separate features and target\n    X_train, y_train = train[feature_columns], train['label']\n    X_dev, y_dev = dev[feature_columns], dev['label']\n    X_eval, y_eval = eval[feature_columns], eval['label']\n\n    # Step 2: Apply SMOTE to balance the training data\n    smote = SMOTE(random_state=42)\n    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\n    # Step 3: Create and train the Random Forest model\n    xgb_model = XGBClassifier(random_state=42)\n    xgb_model.fit(X_train_smote, y_train_smote)\n\n    # Step 4: Evaluate on dev set\n    y_dev_pred = xgb_model.predict(X_dev)\n    y_dev_prob = xgb_model.predict_proba(X_dev)[:, 1]\n    accuracy_dev = accuracy_score(y_dev, y_dev_pred)\n    eer_dev, tdcf_dev = eval_metr(y_dev, y_dev_prob, 0.1588, 2.1007)\n    dev_report = classification_report(y_dev, y_dev_pred)\n    \n    # Step 5: Evaluate on eval set\n    y_eval_pred = xgb_model.predict(X_eval)\n    y_eval_prob = xgb_model.predict_proba(X_eval)[:, 1]\n    accuracy_eval = accuracy_score(y_eval, y_eval_pred)\n    eer_eval, tdcf_eval = eval_metr(y_eval, y_eval_prob, 0.1847, 2.0173)\n    eval_report = classification_report(y_eval, y_eval_pred)\n\n    # Step 6: Print out the results\n    print(\"\\n=== Evaluation on Dev Set ===\")\n    print(f\"Accuracy: {accuracy_dev:.4f}\")\n    print(\"Classification Report:\")\n    print(dev_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on validation data: {eer_dev * 100:.2f}%\")\n    print(f\"Min t-DCF on validation data: {tdcf_dev:.4f}\")\n\n    print(\"\\n=== Evaluation on Eval Set ===\")\n    print(f\"Accuracy: {accuracy_eval:.4f}\")\n    print(\"Classification Report:\")\n    print(eval_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on testing data: {eer_eval * 100:.2f}%\")\n    print(f\"Min t-DCF on testing data: {tdcf_eval:.4f}\")\n\n    # Step 7: Save the trained model\n    joblib.dump(xgb_model, 'xgb_select_model.pkl')\n    print(\"XGBoost model saved as xgb_select_model.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T08:13:55.228025Z","iopub.execute_input":"2025-01-08T08:13:55.228300Z","iopub.status.idle":"2025-01-08T08:13:55.239249Z","shell.execute_reply.started":"2025-01-08T08:13:55.228276Z","shell.execute_reply":"2025-01-08T08:13:55.237775Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb_pipeline_select(train_filtered, dev_filtered, eval_filtered)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T08:13:55.240299Z","iopub.execute_input":"2025-01-08T08:13:55.240689Z","iopub.status.idle":"2025-01-08T08:13:56.052957Z","shell.execute_reply.started":"2025-01-08T08:13:55.240654Z","shell.execute_reply":"2025-01-08T08:13:56.051412Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Bayesian Optimization on Select Features\nBayesian Optimization using optuna","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Optuna Initialization","metadata":{}},{"cell_type":"code","source":"import optuna\nimport joblib\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom xgboost import XGBClassifier\n\nSELECT_FEATURES = ['bit_rate', 'lfcc', 'mindom', 'size', 'spectral_flatness', 'spectral_centroid', 'spectral_mean', 'spectral_rms', 'spectral_spread']\n\ndef prepare_data(train, dev):\n    # Filter datasets using SELECT_FEATURES\n    X_train, y_train = train[SELECT_FEATURES], train['label']\n    X_dev, y_dev = dev[SELECT_FEATURES], dev['label']\n\n    # Apply SMOTE to balance the training data\n    smote = SMOTE(random_state=42)\n    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\n    return X_train_smote, y_train_smote, X_dev, y_dev\n    \ndef objective(trial, model_type, X_train, y_train, X_dev, y_dev):\n    if model_type == 'RandomForest':\n        # Hyperparameters for Random Forest\n        n_estimators = trial.suggest_int('n_estimators', 50, 300)\n        max_depth = trial.suggest_int('max_depth', 10, 100)\n        min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n        min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 5)\n        model = RandomForestClassifier(\n            n_estimators=n_estimators,\n            max_depth=max_depth,\n            min_samples_split=min_samples_split,\n            min_samples_leaf=min_samples_leaf,\n            random_state=42\n        )\n\n    elif model_type == 'AdaBoost':\n        # Hyperparameters for AdaBoost\n        n_estimators = trial.suggest_int('n_estimators', 50, 300)\n        learning_rate = trial.suggest_float('learning_rate', 0.01, 1.0)\n        model = AdaBoostClassifier(\n            n_estimators=n_estimators,\n            learning_rate=learning_rate,\n            random_state=42\n        )\n\n    elif model_type == 'XGBoost':\n        # Hyperparameters for XGBoost\n        n_estimators = trial.suggest_int('n_estimators', 50, 300)\n        max_depth = trial.suggest_int('max_depth', 3, 10)\n        learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)\n        subsample = trial.suggest_float('subsample', 0.5, 1.0)\n        model = XGBClassifier(\n            n_estimators=n_estimators,\n            max_depth=max_depth,\n            learning_rate=learning_rate,\n            subsample=subsample,\n            random_state=42,\n            use_label_encoder=False,\n            eval_metric='logloss'\n        )\n\n    # Train the model\n    model.fit(X_train, y_train)\n    y_dev_prob = model.predict_proba(X_dev)[:, 1]\n    eer, min_tdcf = eval_metr(y_dev, y_dev_prob, C0=0.1588, C1=2.1007)\n\n    return eer\n\n# Function to optimize models using Optuna\ndef optimize_model(train, dev, model_type):\n    X_train, y_train, X_dev, y_dev = prepare_data(train, dev)\n\n    study = optuna.create_study(direction='minimize')  # Minimize EER\n    study.optimize(lambda trial: objective(trial, model_type, X_train, y_train, X_dev, y_dev), n_trials=50)\n\n    print(f\"Best trial for {model_type}: {study.best_trial.params}\")\n    print(f\"Best EER for {model_type}: {study.best_value:.4f}\")\n    return study","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T09:25:02.139478Z","iopub.execute_input":"2025-01-08T09:25:02.140348Z","iopub.status.idle":"2025-01-08T09:25:02.158236Z","shell.execute_reply.started":"2025-01-08T09:25:02.140307Z","shell.execute_reply":"2025-01-08T09:25:02.156046Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Optimize Random Forest\nrf_study = optimize_model(train, eval, 'RandomForest')\n\n# Optimize AdaBoost\nada_study = optimize_model(train, eval, 'AdaBoost')\n\n# Optimize XGBoost\nxgb_study = optimize_model(train, eval, 'XGBoost')\n\n# Save the best model\njoblib.dump(rf_study.best_trial.params, 'best_rf_model_params.pkl')\njoblib.dump(ada_study.best_trial.params, 'best_adaboost_model_params.pkl')\njoblib.dump(xgb_study.best_trial.params, 'best_xgboost_model_params.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T09:25:05.112098Z","iopub.execute_input":"2025-01-08T09:25:05.112480Z","iopub.status.idle":"2025-01-08T09:53:33.386151Z","shell.execute_reply.started":"2025-01-08T09:25:05.112447Z","shell.execute_reply":"2025-01-08T09:53:33.384428Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.2 Feature Selection","metadata":{}},{"cell_type":"code","source":"def filter_features(train, dev, eval):\n    SELECT_FEATURES = ['bit_rate', 'lfcc', 'mindom', 'spectral_flatness', 'spectral_centroid', 'spectral_mean', 'spectral_rms', 'spectral_spread']\n\n    # Step 1: Select only the columns in SELECT_FEATURES plus 'label'\n    selected_columns = SELECT_FEATURES + ['label']\n\n    # Filter the datasets to include only the selected columns\n    train_filtered = train[selected_columns]\n    dev_filtered = dev[selected_columns]\n    eval_filtered = eval[selected_columns]\n\n    return train_filtered, dev_filtered, eval_filtered\n\ntrain_filtered, dev_filtered, eval_filtered = filter_features(train, dev, eval)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T09:53:47.535387Z","iopub.execute_input":"2025-01-08T09:53:47.535945Z","iopub.status.idle":"2025-01-08T09:53:47.547296Z","shell.execute_reply.started":"2025-01-08T09:53:47.535904Z","shell.execute_reply":"2025-01-08T09:53:47.546011Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.3 Random Forest","metadata":{}},{"cell_type":"code","source":"params = {'n_estimators': 191, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5}\ndef rf_pipeline_select(train, dev, eval):\n    # Step 1: Prepare the data\n    feature_columns = [col for col in train.columns if col != 'label']\n    \n    # Function to impute NaN values with column mean\n    def impute_missing_values(df, feature_columns):\n        for col in feature_columns:\n            if df[col].isna().any():\n                print(f\"Column '{col}' contains NaN values. Filling with mean.\")\n                df[col].fillna(df[col].mean(), inplace=True)\n        return df\n    \n    # Impute missing values in train, dev, and eval datasets\n    train = impute_missing_values(train, feature_columns)\n    dev = impute_missing_values(dev, feature_columns)\n    eval = impute_missing_values(eval, feature_columns)\n\n    # Separate features and target\n    X_train, y_train = train[feature_columns], train['label']\n    X_dev, y_dev = dev[feature_columns], dev['label']\n    X_eval, y_eval = eval[feature_columns], eval['label']\n\n    # Step 2: Apply SMOTE to balance the training data\n    smote = SMOTE(random_state=42)\n    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\n    # Step 3: Create and train the Random Forest model\n    rf_model = RandomForestClassifier(random_state=42, **params)\n    rf_model.fit(X_train_smote, y_train_smote)\n\n    # Step 4: Evaluate on dev set\n    y_dev_pred = rf_model.predict(X_dev)\n    y_dev_prob = rf_model.predict_proba(X_dev)[:, 1]\n    accuracy_dev = accuracy_score(y_dev, y_dev_pred)\n    eer_dev, tdcf_dev = eval_metr(y_dev, y_dev_prob, 0.1588, 2.1007)\n    dev_report = classification_report(y_dev, y_dev_pred)\n    \n    # Step 5: Evaluate on eval set\n    y_eval_pred = rf_model.predict(X_eval)\n    y_eval_prob = rf_model.predict_proba(X_eval)[:, 1]\n    accuracy_eval = accuracy_score(y_eval, y_eval_pred)\n    eer_eval, tdcf_eval = eval_metr(y_eval, y_eval_prob, 0.1847, 2.0173)\n    eval_report = classification_report(y_eval, y_eval_pred)\n\n    # Step 6: Print out the results\n    print(\"\\n=== Evaluation on Dev Set ===\")\n    print(f\"Accuracy: {accuracy_dev:.4f}\")\n    print(\"Classification Report:\")\n    print(dev_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on validation data: {eer_dev * 100:.2f}%\")\n    print(f\"Min t-DCF on validation data: {tdcf_dev:.4f}\")\n\n    print(\"\\n=== Evaluation on Eval Set ===\")\n    print(f\"Accuracy: {accuracy_eval:.4f}\")\n    print(\"Classification Report:\")\n    print(eval_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on testing data: {eer_eval * 100:.2f}%\")\n    print(f\"Min t-DCF on testing data: {tdcf_eval:.4f}\")\n\n    # Step 7: Save the trained model\n    joblib.dump(rf_model, 'rf_select_model.pkl')\n    print(\"Random Forest model saved as rf_select_model.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T09:56:01.150452Z","iopub.execute_input":"2025-01-08T09:56:01.150843Z","iopub.status.idle":"2025-01-08T09:56:01.162540Z","shell.execute_reply.started":"2025-01-08T09:56:01.150812Z","shell.execute_reply":"2025-01-08T09:56:01.161194Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rf_pipeline_select(train_filtered, dev_filtered, eval_filtered)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T09:56:01.164740Z","iopub.execute_input":"2025-01-08T09:56:01.165205Z","iopub.status.idle":"2025-01-08T09:56:17.801373Z","shell.execute_reply.started":"2025-01-08T09:56:01.165171Z","shell.execute_reply":"2025-01-08T09:56:17.799772Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.4 AdaBoost","metadata":{}},{"cell_type":"code","source":"params = {'n_estimators': 116, 'learning_rate': 0.05192761614314263}\ndef ada_pipeline_select(train, dev, eval):\n    # Step 1: Prepare the data\n    feature_columns = [col for col in train.columns if col != 'label']\n    \n    # Function to impute NaN values with column mean\n    def impute_missing_values(df, feature_columns):\n        for col in feature_columns:\n            if df[col].isna().any():\n                print(f\"Column '{col}' contains NaN values. Filling with mean.\")\n                df[col].fillna(df[col].mean(), inplace=True)\n        return df\n    \n    # Impute missing values in train, dev, and eval datasets\n    train = impute_missing_values(train, feature_columns)\n    dev = impute_missing_values(dev, feature_columns)\n    eval = impute_missing_values(eval, feature_columns)\n\n    # Separate features and target\n    X_train, y_train = train[feature_columns], train['label']\n    X_dev, y_dev = dev[feature_columns], dev['label']\n    X_eval, y_eval = eval[feature_columns], eval['label']\n\n    # Step 2: Apply SMOTE to balance the training data\n    smote = SMOTE(random_state=42)\n    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\n    # Step 3: Create and train the Random Forest model\n    ada_model = AdaBoostClassifier(random_state=42, **params)\n    ada_model.fit(X_train_smote, y_train_smote)\n\n    # Step 4: Evaluate on dev set\n    y_dev_pred = ada_model.predict(X_dev)\n    y_dev_prob = ada_model.predict_proba(X_dev)[:, 1]\n    accuracy_dev = accuracy_score(y_dev, y_dev_pred)\n    eer_dev, tdcf_dev = eval_metr(y_dev, y_dev_prob, 0.1588, 2.1007)\n    dev_report = classification_report(y_dev, y_dev_pred)\n    \n    # Step 5: Evaluate on eval set\n    y_eval_pred = ada_model.predict(X_eval)\n    y_eval_prob = ada_model.predict_proba(X_eval)[:, 1]\n    accuracy_eval = accuracy_score(y_eval, y_eval_pred)\n    eer_eval, tdcf_eval = eval_metr(y_eval, y_eval_prob, 0.1847, 2.0173)\n    eval_report = classification_report(y_eval, y_eval_pred)\n\n    # Step 6: Print out the results\n    print(\"\\n=== Evaluation on Dev Set ===\")\n    print(f\"Accuracy: {accuracy_dev:.4f}\")\n    print(\"Classification Report:\")\n    print(dev_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on validation data: {eer_dev * 100:.2f}%\")\n    print(f\"Min t-DCF on validation data: {tdcf_dev:.4f}\")\n\n    print(\"\\n=== Evaluation on Eval Set ===\")\n    print(f\"Accuracy: {accuracy_eval:.4f}\")\n    print(\"Classification Report:\")\n    print(eval_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on testing data: {eer_eval * 100:.2f}%\")\n    print(f\"Min t-DCF on testing data: {tdcf_eval:.4f}\")\n\n    # Step 7: Save the trained model\n    joblib.dump(ada_model, 'ada_select_model.pkl')\n    print(\"Adaboost model saved as ada_select_model.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T09:55:50.967477Z","iopub.execute_input":"2025-01-08T09:55:50.967913Z","iopub.status.idle":"2025-01-08T09:55:50.978802Z","shell.execute_reply.started":"2025-01-08T09:55:50.967880Z","shell.execute_reply":"2025-01-08T09:55:50.977567Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ada_pipeline_select(train_filtered, dev_filtered, eval_filtered)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T09:55:51.189418Z","iopub.execute_input":"2025-01-08T09:55:51.189880Z","iopub.status.idle":"2025-01-08T09:56:01.149044Z","shell.execute_reply.started":"2025-01-08T09:55:51.189818Z","shell.execute_reply":"2025-01-08T09:56:01.147855Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.5 XGBoost","metadata":{}},{"cell_type":"code","source":"params = {'n_estimators': 68, 'max_depth': 7, 'learning_rate': 0.026718036292448403, 'subsample': 0.6261578971619668}\ndef xgb_pipeline_select(train, dev, eval):\n    # Step 1: Prepare the data\n    feature_columns = [col for col in train.columns if col != 'label']\n    \n    # Function to impute NaN values with column mean\n    def impute_missing_values(df, feature_columns):\n        for col in feature_columns:\n            if df[col].isna().any():\n                print(f\"Column '{col}' contains NaN values. Filling with mean.\")\n                df[col].fillna(df[col].mean(), inplace=True)\n        return df\n    \n    # Impute missing values in train, dev, and eval datasets\n    train = impute_missing_values(train, feature_columns)\n    dev = impute_missing_values(dev, feature_columns)\n    eval = impute_missing_values(eval, feature_columns)\n\n    # Separate features and target\n    X_train, y_train = train[feature_columns], train['label']\n    X_dev, y_dev = dev[feature_columns], dev['label']\n    X_eval, y_eval = eval[feature_columns], eval['label']\n\n    # Step 2: Apply SMOTE to balance the training data\n    smote = SMOTE(random_state=42)\n    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\n    # Step 3: Create and train the Random Forest model\n    xgb_model = XGBClassifier(random_state=42, **params)\n    xgb_model.fit(X_train_smote, y_train_smote)\n\n    # Step 4: Evaluate on dev set\n    y_dev_pred = xgb_model.predict(X_dev)\n    y_dev_prob = xgb_model.predict_proba(X_dev)[:, 1]\n    accuracy_dev = accuracy_score(y_dev, y_dev_pred)\n    eer_dev, tdcf_dev = eval_metr(y_dev, y_dev_prob, 0.1588, 2.1007)\n    dev_report = classification_report(y_dev, y_dev_pred)\n    \n    # Step 5: Evaluate on eval set\n    y_eval_pred = xgb_model.predict(X_eval)\n    y_eval_prob = xgb_model.predict_proba(X_eval)[:, 1]\n    accuracy_eval = accuracy_score(y_eval, y_eval_pred)\n    eer_eval, tdcf_eval = eval_metr(y_eval, y_eval_prob, 0.1847, 2.0173)\n    eval_report = classification_report(y_eval, y_eval_pred)\n\n    # Step 6: Print out the results\n    print(\"\\n=== Evaluation on Dev Set ===\")\n    print(f\"Accuracy: {accuracy_dev:.4f}\")\n    print(\"Classification Report:\")\n    print(dev_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on validation data: {eer_dev * 100:.2f}%\")\n    print(f\"Min t-DCF on validation data: {tdcf_dev:.4f}\")\n\n    print(\"\\n=== Evaluation on Eval Set ===\")\n    print(f\"Accuracy: {accuracy_eval:.4f}\")\n    print(\"Classification Report:\")\n    print(eval_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on testing data: {eer_eval * 100:.2f}%\")\n    print(f\"Min t-DCF on testing data: {tdcf_eval:.4f}\")\n\n    # Step 7: Save the trained model\n    joblib.dump(xgb_model, 'xgb_select_model.pkl')\n    print(\"XGBoost model saved as xgb_select_model.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T09:54:21.602341Z","iopub.execute_input":"2025-01-08T09:54:21.602723Z","iopub.status.idle":"2025-01-08T09:54:21.614836Z","shell.execute_reply.started":"2025-01-08T09:54:21.602692Z","shell.execute_reply":"2025-01-08T09:54:21.613554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb_pipeline_select(train_filtered, dev_filtered, eval_filtered)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T09:54:21.965061Z","iopub.execute_input":"2025-01-08T09:54:21.965430Z","iopub.status.idle":"2025-01-08T09:54:22.676667Z","shell.execute_reply.started":"2025-01-08T09:54:21.965397Z","shell.execute_reply":"2025-01-08T09:54:22.674786Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Feature Importance","metadata":{}},{"cell_type":"code","source":"import joblib\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import accuracy_score, classification_report\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Shared pipeline function for all models\ndef model_pipeline(train, dev, eval, excluded_columns, model, model_name, eval_metr_params):\n    feature_columns = [col for col in train.columns if col not in excluded_columns]\n\n    def impute_missing_values(df, feature_columns):\n        for col in feature_columns:\n            if df[col].isna().any():\n                print(f\"Column '{col}' contains NaN values. Filling with mean.\")\n                df[col].fillna(df[col].mean(), inplace=True)\n        return df\n\n    train = impute_missing_values(train, feature_columns)\n    dev = impute_missing_values(dev, feature_columns)\n    eval = impute_missing_values(eval, feature_columns)\n\n    X_train, y_train = train[feature_columns], train['label']\n    X_dev, y_dev = dev[feature_columns], dev['label']\n    X_eval, y_eval = eval[feature_columns], eval['label']\n\n    smote = SMOTE(random_state=42)\n    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\n    model.fit(X_train_smote, y_train_smote)\n\n    y_eval_pred = model.predict(X_eval)\n    y_eval_prob = model.predict_proba(X_eval)[:, 1]\n    accuracy_eval = accuracy_score(y_eval, y_eval_pred)\n    eer_eval, tdcf_eval = eval_metr(y_eval, y_eval_prob, *eval_metr_params['eval'])\n    eval_report = classification_report(y_eval, y_eval_pred)\n\n    print(f\"\\n=== {model_name} Evaluation on Eval Set ===\")\n    print(f\"Accuracy: {accuracy_eval:.4f}\")\n    print(\"Classification Report:\")\n    print(eval_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on testing data: {eer_eval * 100:.2f}%\")\n    print(f\"Min t-DCF on testing data: {tdcf_eval:.4f}\")\n\n    # Feature Importance\n    if hasattr(model, 'feature_importances_'):\n        feature_importance = pd.DataFrame({\n            'Feature': feature_columns,\n            'Importance': model.feature_importances_\n        }).sort_values(by='Importance', ascending=False)\n        print(f\"\\n=== {model_name} Feature Importance ===\")\n        print(feature_importance.head(20))\n        # Plot top 20 features\n        top_features = feature_importance.head(20)\n        plt.figure(figsize=(10, 8))\n        plt.barh(top_features['Feature'][::-1], top_features['Importance'][::-1], color='skyblue')\n        plt.xlabel('Importance')\n        plt.title(f'Top 20 Features - {model_name}')\n        plt.tight_layout()\n        plt.show()\n        print(f\"Feature importance plot saved as {model_name.lower()}_feature_importance_plot.png\")\n    else:\n        print(f\"{model_name} does not support feature importance extraction.\")\n\n# Example usage:\neval_metr_params = {\n    'dev': [0.1588, 2.1007],\n    'eval': [0.1847, 2.0173]\n}\n\nexcluded_columns = [\"label\", \"duration\", \"size\", \"spectral_bandwidth\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T04:52:13.618591Z","iopub.execute_input":"2025-01-12T04:52:13.618955Z","iopub.status.idle":"2025-01-12T04:52:13.631107Z","shell.execute_reply.started":"2025-01-12T04:52:13.618925Z","shell.execute_reply":"2025-01-12T04:52:13.630282Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.1 Random Forest","metadata":{}},{"cell_type":"code","source":"# Random Forest\nrandom_forest = RandomForestClassifier(random_state=42)\nmodel_pipeline(train, dev, eval, excluded_columns, random_forest, \"Random Forest\", eval_metr_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T04:52:14.864517Z","iopub.execute_input":"2025-01-12T04:52:14.864869Z","iopub.status.idle":"2025-01-12T04:52:34.831786Z","shell.execute_reply.started":"2025-01-12T04:52:14.864837Z","shell.execute_reply":"2025-01-12T04:52:34.830735Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.2 AdaBoost","metadata":{}},{"cell_type":"code","source":"# AdaBoost\nadaboost = AdaBoostClassifier(random_state=42)\nmodel_pipeline(train, dev, eval, excluded_columns, adaboost, \"AdaBoost\", eval_metr_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T04:52:34.833075Z","iopub.execute_input":"2025-01-12T04:52:34.833404Z","iopub.status.idle":"2025-01-12T04:52:47.358759Z","shell.execute_reply.started":"2025-01-12T04:52:34.833375Z","shell.execute_reply":"2025-01-12T04:52:47.357837Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.3 XGBoost","metadata":{}},{"cell_type":"code","source":"# XGBoost\nxgboost = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\nmodel_pipeline(train, dev, eval, excluded_columns, xgboost, \"XGBoost\", eval_metr_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T04:52:47.360406Z","iopub.execute_input":"2025-01-12T04:52:47.360704Z","iopub.status.idle":"2025-01-12T04:52:49.390766Z","shell.execute_reply.started":"2025-01-12T04:52:47.360676Z","shell.execute_reply":"2025-01-12T04:52:49.389773Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.4 Conclusion\n\n|Feature|XGBoost Importance|Random Forest Importance|AdaBoost Importance|Selected?|\n|-|-|-|-|-|\n|minfun\t|0.119968\t|0.100231\t|0.22\t||\n|spectral_entropy\t|0.119771\t|0.106699\t|0.04\t||\n|meanfun\t|0.049779\t|0.101235\t|0.08\t||\n|mode_frequency\t|0.092469\t|0.089528\t|0.08\t||\n|bit_rate\t|0.027392\t|0.075031\t|0.06\t||\n|peak_frequency\t|N/A\t|0.075427\t|0.20\t||\n|energy\t|0.032100\t|0.075796\t|N/A\t||\n|zcr\t|0.029568\t|0.046573\t|0.04\t||\n|modindex\t|0.020655\t|0.035107\t|0.04\t||\n|dfrange\t|0.020519\t|0.021332\t|0.06\t||","metadata":{}},{"cell_type":"markdown","source":"# 6. Model with Top 10 Features","metadata":{}},{"cell_type":"code","source":"import joblib\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import accuracy_score, classification_report\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Shared pipeline function for all models\ndef model_pipeline(train, dev, eval, excluded_columns, model, model_name, eval_metr_params):\n    selected_features = [\n        \"minfun\", \"spectral_entropy\", \"meanfun\", \"mode_frequency\", \"bit_rate\", \n        \"peak_frequency\", \"energy\", \"zcr\", \"modindex\", \"dfrange\"\n    ]\n\n    def impute_missing_values(df, feature_columns):\n        for col in feature_columns:\n            if df[col].isna().any():\n                print(f\"Column '{col}' contains NaN values. Filling with mean.\")\n                df[col].fillna(df[col].mean(), inplace=True)\n        return df\n\n    train = impute_missing_values(train, selected_features)\n    dev = impute_missing_values(dev, selected_features)\n    eval = impute_missing_values(eval, selected_features)\n\n    X_train, y_train = train[selected_features], train['label']\n    X_dev, y_dev = dev[selected_features], dev['label']\n    X_eval, y_eval = eval[selected_features], eval['label']\n\n    smote = SMOTE(random_state=42)\n    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\n    model.fit(X_train_smote, y_train_smote)\n\n    y_dev_pred = model.predict(X_dev)\n    y_dev_prob = model.predict_proba(X_dev)[:, 1]\n    accuracy_dev = accuracy_score(y_dev, y_dev_pred)\n    eer_dev, tdcf_dev = eval_metr(y_dev, y_dev_prob, *eval_metr_params['dev'])\n    dev_report = classification_report(y_dev, y_dev_pred)\n\n    y_eval_pred = model.predict(X_eval)\n    y_eval_prob = model.predict_proba(X_eval)[:, 1]\n    accuracy_eval = accuracy_score(y_eval, y_eval_pred)\n    eer_eval, tdcf_eval = eval_metr(y_eval, y_eval_prob, *eval_metr_params['eval'])\n    eval_report = classification_report(y_eval, y_eval_pred)\n\n    print(f\"\\n=== {model_name} Evaluation on Dev Set ===\")\n    print(f\"Accuracy: {accuracy_dev:.4f}\")\n    print(\"Classification Report:\")\n    print(dev_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on validation data: {eer_dev * 100:.2f}%\")\n    print(f\"Min t-DCF on validation data: {tdcf_dev:.4f}\")\n\n    print(f\"\\n=== {model_name} Evaluation on Eval Set ===\")\n    print(f\"Accuracy: {accuracy_eval:.4f}\")\n    print(\"Classification Report:\")\n    print(eval_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on testing data: {eer_eval * 100:.2f}%\")\n    print(f\"Min t-DCF on testing data: {tdcf_eval:.4f}\")\n\n    joblib.dump(model, f'{model_name.lower()}_model.pkl')\n    print(f\"{model_name} model saved as {model_name.lower()}_model.pkl\")\n\n    # Feature Importance\n    if hasattr(model, 'feature_importances_'):\n        feature_importance = pd.DataFrame({\n            'Feature': selected_features,\n            'Importance': model.feature_importances_\n        }).sort_values(by='Importance', ascending=False)\n        print(f\"\\n=== {model_name} Feature Importance ===\")\n        print(feature_importance)\n        feature_importance.to_csv(f'{model_name.lower()}_feature_importance.csv', index=False)\n        print(f\"Feature importance saved as {model_name.lower()}_feature_importance.csv\")\n\n        # Plot top features\n        plt.figure(figsize=(10, 8))\n        bars = plt.barh(feature_importance['Feature'][::-1], feature_importance['Importance'][::-1], color='skyblue')\n        plt.xlabel('Importance')\n        plt.title(f'Top Features - {model_name}')\n        plt.tight_layout()\n        plt.savefig(f'{model_name.lower()}_feature_importance_plot.png')\n        plt.show()\n        print(f\"Feature importance plot saved as {model_name.lower()}_feature_importance_plot.png\")\n    else:\n        print(f\"{model_name} does not support feature importance extraction.\")\n\n# Example usage:\neval_metr_params = {\n    'dev': [0.1588, 2.1007],\n    'eval': [0.1847, 2.0173]\n}\n\nexcluded_columns = [\"label\", \"duration\", \"size\", \"spectral_bandwidth\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T05:08:53.158622Z","iopub.execute_input":"2025-01-12T05:08:53.159013Z","iopub.status.idle":"2025-01-12T05:08:53.172290Z","shell.execute_reply.started":"2025-01-12T05:08:53.158979Z","shell.execute_reply":"2025-01-12T05:08:53.171305Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6.1 Random Forest","metadata":{}},{"cell_type":"code","source":"# Random Forest\nrandom_forest = RandomForestClassifier(random_state=42)\nmodel_pipeline(train, dev, eval, excluded_columns, random_forest, \"Random Forest\", eval_metr_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T05:08:59.876392Z","iopub.execute_input":"2025-01-12T05:08:59.876720Z","iopub.status.idle":"2025-01-12T05:09:14.341837Z","shell.execute_reply.started":"2025-01-12T05:08:59.876694Z","shell.execute_reply":"2025-01-12T05:09:14.340855Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6.2 AdaBoost","metadata":{}},{"cell_type":"code","source":"# AdaBoost\nadaboost = AdaBoostClassifier(random_state=42)\nmodel_pipeline(train, dev, eval, excluded_columns, adaboost, \"AdaBoost\", eval_metr_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T05:09:14.343204Z","iopub.execute_input":"2025-01-12T05:09:14.343683Z","iopub.status.idle":"2025-01-12T05:09:18.879064Z","shell.execute_reply.started":"2025-01-12T05:09:14.343596Z","shell.execute_reply":"2025-01-12T05:09:18.878030Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6.3 XGBoost","metadata":{}},{"cell_type":"code","source":"# XGBoost\nxgboost = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\nmodel_pipeline(train, dev, eval, excluded_columns, xgboost, \"XGBoost\", eval_metr_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T05:09:18.880619Z","iopub.execute_input":"2025-01-12T05:09:18.880990Z","iopub.status.idle":"2025-01-12T05:09:19.947974Z","shell.execute_reply.started":"2025-01-12T05:09:18.880952Z","shell.execute_reply":"2025-01-12T05:09:19.946925Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. Oversampling","metadata":{}},{"cell_type":"code","source":"import joblib\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.metrics import accuracy_score, classification_report\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Shared pipeline function for all models with oversampling and undersampling options\ndef model_pipeline_balanced(train, dev, eval, excluded_columns, model, model_name, eval_metr_params, resampling_method='smote'):\n    selected_features = [\n        \"minfun\", \"spectral_entropy\", \"meanfun\", \"mode_frequency\", \"bit_rate\", \n        \"peak_frequency\", \"energy\", \"zcr\", \"modindex\", \"dfrange\"\n    ]\n\n    def impute_missing_values(df, feature_columns):\n        for col in feature_columns:\n            if df[col].isna().any():\n                print(f\"Column '{col}' contains NaN values. Filling with mean.\")\n                df[col].fillna(df[col].mean(), inplace=True)\n        return df\n\n    train = impute_missing_values(train, selected_features)\n    dev = impute_missing_values(dev, selected_features)\n    eval = impute_missing_values(eval, selected_features)\n\n    X_train, y_train = train[selected_features], train['label']\n    X_dev, y_dev = dev[selected_features], dev['label']\n    X_eval, y_eval = eval[selected_features], eval['label']\n\n    # Apply resampling method (SMOTE or undersampling)\n    if resampling_method == 'smote':\n        resampler = SMOTE(random_state=42)\n        X_train_resampled, y_train_resampled = resampler.fit_resample(X_train, y_train)\n    elif resampling_method == 'undersample':\n        resampler = RandomUnderSampler(random_state=42)\n        X_train_resampled, y_train_resampled = resampler.fit_resample(X_train, y_train)\n    else:\n        raise ValueError(f\"Unsupported resampling method: {resampling_method}\")\n\n    # Train the model\n    model.fit(X_train_resampled, y_train_resampled)\n\n    # Evaluate on the evaluation set\n    y_eval_pred = model.predict(X_eval)\n    y_eval_prob = model.predict_proba(X_eval)[:, 1]\n    accuracy_eval = accuracy_score(y_eval, y_eval_pred)\n    eer_eval, tdcf_eval = eval_metr(y_eval, y_eval_prob, *eval_metr_params['eval'])\n    eval_report = classification_report(y_eval, y_eval_pred)\n\n    print(f\"\\n=== {model_name} Evaluation on Eval Set using {resampling_method.upper()} ===\")\n    print(f\"Accuracy: {accuracy_eval:.4f}\")\n    print(\"Classification Report:\")\n    print(eval_report)\n    print(\"Custom Eval Metrics:\")\n    print(f\"EER on testing data: {eer_eval * 100:.2f}%\")\n    print(f\"Min t-DCF on testing data: {tdcf_eval:.4f}\")\n\n# Example usage with both SMOTE and undersampling:\neval_metr_params = {\n    'dev': [0.1588, 2.1007],\n    'eval': [0.1847, 2.0173]\n}\n\nexcluded_columns = [\"label\", \"duration\", \"size\", \"spectral_bandwidth\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T07:14:08.707187Z","iopub.execute_input":"2025-01-12T07:14:08.707527Z","iopub.status.idle":"2025-01-12T07:14:08.718749Z","shell.execute_reply.started":"2025-01-12T07:14:08.707501Z","shell.execute_reply":"2025-01-12T07:14:08.717645Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7.1 Random Forest","metadata":{}},{"cell_type":"code","source":"rf_model = RandomForestClassifier(random_state=42)\nmodel_pipeline_balanced(train, dev, eval, excluded_columns, rf_model, \"Random Forest\", eval_metr_params, resampling_method='undersample')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T07:16:51.662201Z","iopub.execute_input":"2025-01-12T07:16:51.662543Z","iopub.status.idle":"2025-01-12T07:16:54.617434Z","shell.execute_reply.started":"2025-01-12T07:16:51.662516Z","shell.execute_reply":"2025-01-12T07:16:54.616090Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7.2 AdaBoost","metadata":{}},{"cell_type":"code","source":"# AdaBoost\nadaboost = AdaBoostClassifier(random_state=42)\nmodel_pipeline_balanced(train, dev, eval, excluded_columns, adaboost, \"AdaBoost\", eval_metr_params, resampling_method='undersample')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T07:16:54.619034Z","iopub.execute_input":"2025-01-12T07:16:54.619408Z","iopub.status.idle":"2025-01-12T07:16:55.865008Z","shell.execute_reply.started":"2025-01-12T07:16:54.619373Z","shell.execute_reply":"2025-01-12T07:16:55.863923Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7.3 XGBoost","metadata":{}},{"cell_type":"code","source":"# XGBoost\nxgboost = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\nmodel_pipeline_balanced(train, dev, eval, excluded_columns, adaboost, \"XGBoost\", eval_metr_params, resampling_method='undersample')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T07:16:55.866696Z","iopub.execute_input":"2025-01-12T07:16:55.867116Z","iopub.status.idle":"2025-01-12T07:16:57.102354Z","shell.execute_reply.started":"2025-01-12T07:16:55.867061Z","shell.execute_reply":"2025-01-12T07:16:57.101499Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 8. System Specific Features","metadata":{}},{"cell_type":"markdown","source":"## 8.1 All System ID","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n# ganti dataset ngikut upload nnti\ntrain = pd.read_csv(\"/kaggle/input/borzi-full/train_set.csv\")\ndev = pd.read_csv(\"/kaggle/input/borzi-full/dev_set.csv\")\neval = pd.read_csv(\"/kaggle/input/borzi-full/eval_set.csv\")\n\n# Ganti value label\ntrain['label'] = train['label'].map({'bonafide': 1, 'spoof': 0})\ndev['label'] = dev['label'].map({'bonafide': 1, 'spoof': 0})\neval['label'] = eval['label'].map({'bonafide': 1, 'spoof': 0})\n\ndata = pd.concat([train, dev, eval], axis=0, ignore_index=True, join='outer')\n\n# Drop col gk penting\ndata = data.drop(['AUDIO_FILE_NAME', \"duration\", \"size\", \"spectral_bandwidth\"], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T12:33:17.694174Z","iopub.execute_input":"2025-05-18T12:33:17.694581Z","iopub.status.idle":"2025-05-18T12:33:21.043665Z","shell.execute_reply.started":"2025-05-18T12:33:17.694549Z","shell.execute_reply":"2025-05-18T12:33:21.042498Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = data.drop('label', axis=1)\ny = data['label']\n\nX_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.30, random_state=42, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T12:33:23.332279Z","iopub.execute_input":"2025-05-18T12:33:23.332622Z","iopub.status.idle":"2025-05-18T12:33:23.457483Z","shell.execute_reply.started":"2025-05-18T12:33:23.332595Z","shell.execute_reply":"2025-05-18T12:33:23.456261Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T12:33:24.981816Z","iopub.execute_input":"2025-05-18T12:33:24.982245Z","iopub.status.idle":"2025-05-18T12:33:24.989105Z","shell.execute_reply.started":"2025-05-18T12:33:24.982213Z","shell.execute_reply":"2025-05-18T12:33:24.987838Z"}},"outputs":[{"name":"stdout","text":"(85022, 47)\n(36438, 47)\n(85022,)\n(36438,)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### 8.1.1 Evaluation & Feature Importance\n- Random Forest\n- AdaBoost\n- XGBoost","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, roc_curve\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\n\n# Handle missing values\ndef handle_missing_values(data):\n    for column in data.columns:\n        if data[column].isnull().sum() > 0:\n            if data[column].dtype in ['int64', 'float64']:\n                data[column].fillna(data[column].mean(), inplace=True)\n            else:\n                data[column].fillna(data[column].mode()[0], inplace=True)\n    return data\n\n\n# Evaluate model performance\ndef evaluate_model(model, model_name, X_train, y_train, X_test, y_test):\n    print(f\"\\n=== Evaluating {model_name} ===\")\n    \n    # Train the model\n    model.fit(X_train, y_train)\n    \n    # Predictions\n    y_pred = model.predict(X_test)\n    y_pred_probs = model.predict_proba(X_test)[:, 1]\n    \n    # Metrics\n    accuracy = accuracy_score(y_test, y_pred)\n    report = classification_report(y_test, y_pred)\n    fpr, tpr, _ = roc_curve(y_test, y_pred_probs)\n    eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n    \n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(\"Classification Report:\")\n    print(report)\n    print(f\"EER: {eer * 100:.2f}%\")\n    \n    return model\n\n# Train and test models on all SYSTEM_IDs\ndef train_and_test_all_system_ids(data):\n    # Handle missing values\n    data = handle_missing_values(data)\n    \n    # Get unique SYSTEM_IDs\n    system_ids = data['SYSTEM_ID'].unique()\n    system_ids = [sid for sid in system_ids if sid != 'bonafide']  # Exclude 'bonafide'\n\n    models = {\n        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n        \"AdaBoost\": AdaBoostClassifier(n_estimators=100, random_state=42),\n        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n    }\n\n    # Dictionary to store trained models for feature importance\n    trained_models = {}\n\n    for sid in system_ids:\n        print(f\"\\n=== SYSTEM_ID: {sid} ===\")\n        \n        # Filter data for bonafide and the current SYSTEM_ID\n        subset = data[(data['SYSTEM_ID'] == sid) | (data['SYSTEM_ID'] == 'bonafide')]\n        \n        # Show distribution of labels\n        # print(subset['SYSTEM_ID'].value_counts())\n        \n        # Prepare features and labels\n        X = subset.drop(['label', 'SYSTEM_ID'], axis=1)\n        y = subset['label']\n        feature_columns = X.columns  # Dynamically extract features for this subset\n\n        # Print feature names and preview the data\n        # print(f\"Features for SYSTEM_ID {sid}: {list(feature_columns)}\")\n        # print(f\"First rows of features for SYSTEM_ID {sid}:\\n{X.head()}\")\n        \n        # Split data into train and test sets\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, shuffle=True)\n        \n        for model_name, model in models.items():\n            print(f\"\\n--- Evaluating {model_name} for SYSTEM_ID: {sid} ---\")\n            trained_model = evaluate_model(model, model_name, X_train, y_train, X_test, y_test)\n            print('\\n')\n            # Print trained model parameters\n            # print(f\"Trained {model_name} parameters for SYSTEM_ID {sid}:\\n{trained_model.get_params()}\")\n            \n            # # Extract and print feature importances\n            # if hasattr(trained_model, 'feature_importances_'):\n            #     feature_importances = trained_model.feature_importances_\n            #     feature_importance_df = pd.DataFrame({\n            #         'Feature': feature_columns,\n            #         'Importance': feature_importances\n            #     }).sort_values(by='Importance', ascending=False).head(20)\n            #     print(f\"Top 20 Feature Importances for {model_name}, SYSTEM_ID {sid}:\\n{feature_importance_df}\")\n            \n            # # Store the trained model and subset-specific features\n            # trained_models[(sid, model_name)] = (trained_model, feature_columns)\n    \n    return trained_models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T12:33:28.554367Z","iopub.execute_input":"2025-05-18T12:33:28.554747Z","iopub.status.idle":"2025-05-18T12:33:29.373175Z","shell.execute_reply.started":"2025-05-18T12:33:28.554715Z","shell.execute_reply":"2025-05-18T12:33:29.372011Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"trained_models = train_and_test_all_system_ids(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T12:33:39.509574Z","iopub.execute_input":"2025-05-18T12:33:39.510194Z","iopub.status.idle":"2025-05-18T12:34:14.741527Z","shell.execute_reply.started":"2025-05-18T12:33:39.510147Z","shell.execute_reply":"2025-05-18T12:34:14.739436Z"}},"outputs":[{"name":"stdout","text":"\n=== SYSTEM_ID: A01 ===\n\n--- Evaluating Random Forest for SYSTEM_ID: A01 ---\n\n=== Evaluating Random Forest ===\nAccuracy: 0.9763\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.97      0.97      0.97      2279\n           1       0.98      0.98      0.98      3721\n\n    accuracy                           0.98      6000\n   macro avg       0.98      0.97      0.97      6000\nweighted avg       0.98      0.98      0.98      6000\n\nEER: 2.68%\n\n\n\n--- Evaluating AdaBoost for SYSTEM_ID: A01 ---\n\n=== Evaluating AdaBoost ===\nAccuracy: 0.9707\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.96      0.96      0.96      2279\n           1       0.97      0.98      0.98      3721\n\n    accuracy                           0.97      6000\n   macro avg       0.97      0.97      0.97      6000\nweighted avg       0.97      0.97      0.97      6000\n\nEER: 3.03%\n\n\n\n--- Evaluating XGBoost for SYSTEM_ID: A01 ---\n\n=== Evaluating XGBoost ===\nAccuracy: 0.9843\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.98      0.98      0.98      2279\n           1       0.99      0.99      0.99      3721\n\n    accuracy                           0.98      6000\n   macro avg       0.98      0.98      0.98      6000\nweighted avg       0.98      0.98      0.98      6000\n\nEER: 1.54%\n\n\n\n=== SYSTEM_ID: A02 ===\n\n--- Evaluating Random Forest for SYSTEM_ID: A02 ---\n\n=== Evaluating Random Forest ===\nAccuracy: 0.9995\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      2279\n           1       1.00      1.00      1.00      3721\n\n    accuracy                           1.00      6000\n   macro avg       1.00      1.00      1.00      6000\nweighted avg       1.00      1.00      1.00      6000\n\nEER: 0.00%\n\n\n\n--- Evaluating AdaBoost for SYSTEM_ID: A02 ---\n\n=== Evaluating AdaBoost ===\nAccuracy: 0.9995\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      2279\n           1       1.00      1.00      1.00      3721\n\n    accuracy                           1.00      6000\n   macro avg       1.00      1.00      1.00      6000\nweighted avg       1.00      1.00      1.00      6000\n\nEER: 0.00%\n\n\n\n--- Evaluating XGBoost for SYSTEM_ID: A02 ---\n\n=== Evaluating XGBoost ===\nAccuracy: 0.9995\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      2279\n           1       1.00      1.00      1.00      3721\n\n    accuracy                           1.00      6000\n   macro avg       1.00      1.00      1.00      6000\nweighted avg       1.00      1.00      1.00      6000\n\nEER: 0.00%\n\n\n\n=== SYSTEM_ID: A03 ===\n\n--- Evaluating Random Forest for SYSTEM_ID: A03 ---\n\n=== Evaluating Random Forest ===\nAccuracy: 1.0000\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      2279\n           1       1.00      1.00      1.00      3721\n\n    accuracy                           1.00      6000\n   macro avg       1.00      1.00      1.00      6000\nweighted avg       1.00      1.00      1.00      6000\n\nEER: 0.00%\n\n\n\n--- Evaluating AdaBoost for SYSTEM_ID: A03 ---\n\n=== Evaluating AdaBoost ===\nAccuracy: 0.9998\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      2279\n           1       1.00      1.00      1.00      3721\n\n    accuracy                           1.00      6000\n   macro avg       1.00      1.00      1.00      6000\nweighted avg       1.00      1.00      1.00      6000\n\nEER: 0.00%\n\n\n\n--- Evaluating XGBoost for SYSTEM_ID: A03 ---\n\n=== Evaluating XGBoost ===\nAccuracy: 1.0000\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      2279\n           1       1.00      1.00      1.00      3721\n\n    accuracy                           1.00      6000\n   macro avg       1.00      1.00      1.00      6000\nweighted avg       1.00      1.00      1.00      6000\n\nEER: 0.00%\n\n\n\n=== SYSTEM_ID: A04 ===\n\n--- Evaluating Random Forest for SYSTEM_ID: A04 ---\n\n=== Evaluating Random Forest ===\nAccuracy: 0.9227\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.91      0.88      0.90      2279\n           1       0.93      0.95      0.94      3721\n\n    accuracy                           0.92      6000\n   macro avg       0.92      0.91      0.92      6000\nweighted avg       0.92      0.92      0.92      6000\n\nEER: 8.60%\n\n\n\n--- Evaluating AdaBoost for SYSTEM_ID: A04 ---\n\n=== Evaluating AdaBoost ===\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-05fddce7d137>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_test_all_system_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-7dd51c13125d>\u001b[0m in \u001b[0;36mtrain_and_test_all_system_ids\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n--- Evaluating {model_name} for SYSTEM_ID: {sid} ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;31m# Print trained model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-7dd51c13125d>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, model_name, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;31m# Boosting step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             sample_weight, estimator_weight, estimator_error = self._boost(\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \"\"\"\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"SAMME.R\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":6},{"cell_type":"markdown","source":"# 9. Select SYSTEM_ID","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport warnings\nfrom sklearn.metrics import accuracy_score, classification_report, roc_curve\nfrom sklearn.model_selection import train_test_split\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T12:33:08.281329Z","iopub.execute_input":"2025-05-18T12:33:08.281620Z","iopub.status.idle":"2025-05-18T12:33:10.376002Z","shell.execute_reply.started":"2025-05-18T12:33:08.281591Z","shell.execute_reply":"2025-05-18T12:33:10.374992Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Load datasets\ntrain = pd.read_csv(\"/kaggle/input/borzi-full/train_set.csv\")\ndev = pd.read_csv(\"/kaggle/input/borzi-full/dev_set.csv\")\neval = pd.read_csv(\"/kaggle/input/borzi-full/eval_set.csv\")\n\n# Ganti value label\ntrain['label'] = train['label'].map({'bonafide': 1, 'spoof': 0})\ndev['label'] = dev['label'].map({'bonafide': 1, 'spoof': 0})\neval['label'] = eval['label'].map({'bonafide': 1, 'spoof': 0})\n\n# Concatenate train and eval sets\ndata = pd.concat([train, eval], axis=0, ignore_index=True, join='outer')\n\n# Handle missing values function\ndef handle_missing_values(data):\n    for column in data.columns:\n        if data[column].isnull().sum() > 0:\n            if data[column].dtype in ['int64', 'float64']:\n                data[column].fillna(data[column].mean(), inplace=True)\n            else:\n                data[column].fillna(data[column].mode()[0], inplace=True)\n    return data\n\n# Handle the missing value\ndata = handle_missing_values(data)\n\n# Drop unnecessary columns\ndata = data.drop(['AUDIO_FILE_NAME', \"duration\", \"size\", \"spectral_bandwidth\"], axis=1) # msrcc & psrcc karena null\n\n# Filter SYSTEM_ID to keep only specific values\nvalid_system_ids = [\"A06\", \"A19\"]\ndata = data[~data[\"SYSTEM_ID\"].isin(valid_system_ids)] # ~ buat exclude\n\n# Drop SYSTEM_ID column after filtering\ndata = data.drop(columns=[\"SYSTEM_ID\"])\n\n# Split features and labels\nX = data.drop('label', axis=1)\ny = data['label']\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=24, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:03:07.259195Z","iopub.execute_input":"2025-03-10T13:03:07.259540Z","iopub.status.idle":"2025-03-10T13:03:08.836741Z","shell.execute_reply.started":"2025-03-10T13:03:07.259514Z","shell.execute_reply":"2025-03-10T13:03:08.835603Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9.1 Normal set","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# List of models to evaluate\nmodels = {\n    \"Random Forest\": RandomForestClassifier(random_state=42, n_estimators=100),\n    \"AdaBoost\": AdaBoostClassifier(random_state=42, n_estimators=100),\n    \"XGBoost\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"logloss\")\n}\n\n# Loop through each model\nfor model_name, model in models.items():\n    print(f\"\\n===== {model_name} =====\")\n    \n    # Train the model\n    model.fit(X_train, y_train)\n    \n    # Predictions\n    y_pred = model.predict(X_test)\n    y_pred_probs = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n    \n    # Metrics\n    accuracy = accuracy_score(y_test, y_pred)\n    eer = eval_metr(y_test, y_pred)\n    report = classification_report(y_test, y_pred)\n    \n    # Print results\n    print(f\"{model_name} Accuracy: {accuracy * 100:.2f}%\")\n    print(f\"{model_name} EER: {eer * 100:.2f}%\")\n    print(report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:03:08.838413Z","iopub.execute_input":"2025-03-10T13:03:08.838886Z","iopub.status.idle":"2025-03-10T13:04:14.839581Z","shell.execute_reply.started":"2025-03-10T13:03:08.838833Z","shell.execute_reply":"2025-03-10T13:04:14.838435Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9.2 Oversampling","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nsmote = SMOTE(sampling_strategy=0.5, random_state=42)  # Adjust ratio as needed\nX_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T13:23:19.213720Z","iopub.execute_input":"2025-02-02T13:23:19.214229Z","iopub.status.idle":"2025-02-02T13:23:19.783263Z","shell.execute_reply.started":"2025-02-02T13:23:19.214195Z","shell.execute_reply":"2025-02-02T13:23:19.781467Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# List of models to evaluate\nmodels = {\n    \"Random Forest\": RandomForestClassifier(random_state=42, n_estimators=100),\n    \"AdaBoost\": AdaBoostClassifier(random_state=42, n_estimators=100),\n    \"XGBoost\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"logloss\")\n}\n\n# Loop through each model\nfor model_name, model in models.items():\n    print(f\"\\n===== {model_name} =====\")\n    \n    # Train the model\n    model.fit(X_train_smote, y_train_smote)\n    \n    # Predictions\n    y_pred = model.predict(X_test)\n    y_pred_probs = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n    \n    # Metrics\n    accuracy = accuracy_score(y_test, y_pred)\n    eer, _ = eval_metr(y_test, y_pred, 0.1847, 2.0173)\n    report = classification_report(y_test, y_pred)\n    \n    # Print results\n    print(f\"{model_name} Accuracy: {accuracy * 100:.2f}%\")\n    print(f\"{model_name} EER: {eer * 100:.2f}%\")\n    print(report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T13:23:31.940618Z","iopub.execute_input":"2025-02-02T13:23:31.941182Z","iopub.status.idle":"2025-02-02T13:24:22.920273Z","shell.execute_reply.started":"2025-02-02T13:23:31.941128Z","shell.execute_reply":"2025-02-02T13:24:22.918652Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9.3 Undersampling","metadata":{}},{"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\nundersampler  = RandomUnderSampler(sampling_strategy=0.5, random_state=42)  # Adjust ratio as needed\nX_train_resampled, y_train_resampled = undersampler .fit_resample(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T13:25:39.460357Z","iopub.execute_input":"2025-02-02T13:25:39.460914Z","iopub.status.idle":"2025-02-02T13:25:39.505551Z","shell.execute_reply.started":"2025-02-02T13:25:39.460874Z","shell.execute_reply":"2025-02-02T13:25:39.503096Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# List of models to evaluate\nmodels = {\n    \"Random Forest\": RandomForestClassifier(random_state=42, n_estimators=100),\n    \"AdaBoost\": AdaBoostClassifier(random_state=42, n_estimators=100),\n    \"XGBoost\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"logloss\")\n}\n\n# Loop through each model\nfor model_name, model in models.items():\n    print(f\"\\n===== {model_name} =====\")\n    \n    # Train the model\n    model.fit(X_train_resampled, y_train_resampled)\n    \n    # Predictions\n    y_pred = model.predict(X_test)\n    y_pred_probs = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n    \n    # Metrics\n    accuracy = accuracy_score(y_test, y_pred)\n    eer, _ = eval_metr(y_test, y_pred, 0.1847, 2.0173)\n    report = classification_report(y_test, y_pred)\n    \n    # Print results\n    print(f\"{model_name} Accuracy: {accuracy * 100:.2f}%\")\n    print(f\"{model_name} EER: {eer * 100:.2f}%\")\n    print(report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T13:25:49.403300Z","iopub.execute_input":"2025-02-02T13:25:49.403671Z","iopub.status.idle":"2025-02-02T13:26:13.413095Z","shell.execute_reply.started":"2025-02-02T13:25:49.403643Z","shell.execute_reply":"2025-02-02T13:26:13.412006Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 10. Not Joining Eval to the set (Eval is for testing only)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport warnings\nfrom sklearn.metrics import accuracy_score, classification_report, roc_curve\nfrom sklearn.model_selection import train_test_split\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:05:05.006176Z","iopub.execute_input":"2025-03-10T13:05:05.006554Z","iopub.status.idle":"2025-03-10T13:05:05.012279Z","shell.execute_reply.started":"2025-03-10T13:05:05.006520Z","shell.execute_reply":"2025-03-10T13:05:05.010992Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report, roc_curve, accuracy_score\ndef eval_metr(y_true, y_pred, C0, C1, P_target=0.5):\n    # Compute ROC curve\n    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n    fnr = 1 - tpr  # False Negative Rate (Miss Rate)\n\n    # Compute EER\n    abs_diff = np.abs(fpr - fnr)\n    eer_index = np.argmin(abs_diff)\n    eer = (fpr[eer_index] + fnr[eer_index]) / 2\n\n    # Compute t-DCF\n    pi_spoof = P_target  # Prior for spoof\n    pi_bonafide = 1 - P_target  # Prior for bonafide\n\n    # Calculate t-DCF values\n    tdcf_values = (pi_bonafide * C0 * fnr + pi_spoof * C1 * fpr) / min(pi_bonafide * C0, pi_spoof * C1)\n\n    # Find minimum t-DCF\n    min_tdcf = np.min(tdcf_values)\n\n    return eer, min_tdcf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:05:05.200700Z","iopub.execute_input":"2025-03-10T13:05:05.201082Z","iopub.status.idle":"2025-03-10T13:05:05.208344Z","shell.execute_reply.started":"2025-03-10T13:05:05.201050Z","shell.execute_reply":"2025-03-10T13:05:05.207157Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load datasets\ntrain = pd.read_csv(\"/kaggle/input/borzi-full/train_set.csv\")\neval = pd.read_csv(\"/kaggle/input/borzi-full/eval_set.csv\")\n\n# Map labels\ntrain['label'] = train['label'].map({'bonafide': 1, 'spoof': 0})\neval['label'] = eval['label'].map({'bonafide': 1, 'spoof': 0})\nvalid_system_ids = [\"A06\", \"A17\", \"A19\"]\n\n# Handle missing values function\ndef handle_missing_values(data):\n    for column in data.columns:\n        if data[column].isnull().sum() > 0:\n            if data[column].dtype in ['int64', 'float64']:\n                data[column].fillna(data[column].mean(), inplace=True)\n            else:\n                data[column].fillna(data[column].mode()[0], inplace=True)\n    return data\n\ndef train_test_filter(df):\n    # Handle the missing value\n    df = handle_missing_values(df)\n    # Drop col null atau gk penting\n    df = df.drop(['AUDIO_FILE_NAME', \"duration\", \"size\", \"spectral_bandwidth\"], axis=1) # msrcc & psrcc karena null\n    # Filter System_id\n    df = df[~df[\"SYSTEM_ID\"].isin(valid_system_ids)] # ~ buat exclude\n    # Drop system_id setelah di filter\n    df = df.drop(columns=[\"SYSTEM_ID\"])\n\n    X = df.drop('label', axis=1)\n    y = df['label']\n    \n    return X, y\n\nX_train, y_train = train_test_filter(train)\nX_test, y_test = train_test_filter(eval)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:06:20.886644Z","iopub.execute_input":"2025-03-10T13:06:20.887051Z","iopub.status.idle":"2025-03-10T13:06:22.352662Z","shell.execute_reply.started":"2025-03-10T13:06:20.887018Z","shell.execute_reply":"2025-03-10T13:06:22.351581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:06:24.628371Z","iopub.execute_input":"2025-03-10T13:06:24.628706Z","iopub.status.idle":"2025-03-10T13:06:24.634777Z","shell.execute_reply.started":"2025-03-10T13:06:24.628679Z","shell.execute_reply":"2025-03-10T13:06:24.633827Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# List of models to evaluate\nmodels = {\n    \"Random Forest\": RandomForestClassifier(random_state=42, n_estimators=100),\n    \"AdaBoost\": AdaBoostClassifier(random_state=42, n_estimators=100),\n    \"XGBoost\": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"logloss\")\n}\n\n# Loop through each model\nfor model_name, model in models.items():\n    print(f\"\\n===== {model_name} =====\")\n    \n    # Train the model\n    model.fit(X_train, y_train)\n    \n    # Predictions\n    y_pred = model.predict(X_test)\n    y_pred_probs = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n    \n    # Metrics\n    accuracy = accuracy_score(y_test, y_pred)\n    eer, _ = eval_metr(y_test, y_pred, 0.1847, 2.0173)\n    report = classification_report(y_test, y_pred)\n    \n    # Print results\n    print(f\"{model_name} Accuracy: {accuracy * 100:.2f}%\")\n    print(f\"{model_name} EER: {eer * 100:.2f}%\")\n    print(report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T13:06:26.837371Z","iopub.execute_input":"2025-03-10T13:06:26.837726Z","iopub.status.idle":"2025-03-10T13:06:50.727334Z","shell.execute_reply.started":"2025-03-10T13:06:26.837698Z","shell.execute_reply":"2025-03-10T13:06:50.726467Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 11. Feature Importance on Spoofing Methods Only","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom xgboost import XGBClassifier\n\ndef process_and_select_features(train, dev, eval, excluded_columns, system_id_list):\n    # Combine datasets\n    data = pd.concat([train, dev, eval], ignore_index=True)\n    \n    # Filter based on system_id_list\n    data = data[data['SYSTEM_ID'].astype(str).isin(system_id_list)]\n    data = data.drop(columns=['SYSTEM_ID'])\n    \n    # Identify feature columns\n    feature_columns = [col for col in data.columns if col not in excluded_columns + ['label']]\n    \n    # Impute missing values\n    def impute_missing_values(df, feature_columns):\n        imputer = SimpleImputer(strategy='mean')\n        df[feature_columns] = imputer.fit_transform(df[feature_columns])\n        return df\n    \n    data = impute_missing_values(data, feature_columns)\n    \n    # Encode labels\n    data['label'] = data['label'].replace({\"bonafide\": 1, \"spoof\": 0})\n    data = data.dropna(subset=['label'])\n    data['label'] = data['label'].astype(int)\n    \n    # Feature importance calculation\n    models = {\n        'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n        'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=42),\n        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n    }\n    \n    X = data[feature_columns]\n    y = data['label']\n    \n    feature_importance_df = pd.DataFrame()\n    feature_importance_df['Num'] = range(1, 21)  # Top 20 features\n    \n    for model_name, model in models.items():\n        model.fit(X, y)\n        feature_importance = model.feature_importances_\n        sorted_indices = np.argsort(feature_importance)[::-1][:20]  # Top 20 features\n        top_features = [feature_columns[i] for i in sorted_indices]\n        top_scores = [feature_importance[i] for i in sorted_indices]\n        \n        feature_importance_df[model_name] = [f\"{f} ({s:.4f})\" for f, s in zip(top_features, top_scores)]\n    \n    return feature_importance_df\n\nexcluded_columns = [\"label\", \"duration\", \"size\", \"spectral_bandwidth\"]\n# system_id_list = [\"bonafide\", \"A01\", \"A02\", \"A03\", \"A04\", \"A07\", \"A08\", \"A09\", \"A10\", \"A11\", \"A12\", \"A16\"]  # TTS\n# system_id_list = [\"bonafide\", \"A05\", \"A06\", \"A17\", \"A18\", \"A19\"]  # VC\nsystem_id_list = [\"bonafide\", \"A13\", \"A14\", \"A15\"]  # TTS_VC","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T15:15:03.024204Z","iopub.execute_input":"2025-02-28T15:15:03.024559Z","iopub.status.idle":"2025-02-28T15:15:03.035334Z","shell.execute_reply.started":"2025-02-28T15:15:03.024523Z","shell.execute_reply":"2025-02-28T15:15:03.034096Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"process_and_select_features(train, dev, eval, excluded_columns, system_id_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T15:15:03.349333Z","iopub.execute_input":"2025-02-28T15:15:03.349718Z","iopub.status.idle":"2025-02-28T15:15:24.734005Z","shell.execute_reply.started":"2025-02-28T15:15:03.349684Z","shell.execute_reply":"2025-02-28T15:15:24.731554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}